{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shree-Mh/Project/blob/main/ansi2025/ANAIS_2025_Lab_Answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOZbwrrWgrdG"
      },
      "source": [
        "# Medical LLM Fine-Tuning Tutorial\n",
        "\n",
        "<img src=\"https://sbilab.iiitd.edu.in/img/logo_new.png\" alt=\"SBILab Logo\" width=\"100\">\n",
        "<img src=\"https://www.iiitd.ac.in/sites/default/files/images/logo/style3colorlarge.png\" alt=\"IIIT Delhi Logo\" height=\"100\">\n",
        "\n",
        "## By Jivitesh Sabharwal, PhD Scholar at IIIT Delhi\n",
        "Guided by **Prof. Anubha Gupta**\n",
        "\n",
        "\n",
        "## Objective of the Tutorial\n",
        "\n",
        "The primary objective of this tutorial is to provide a **hands-on, end-to-end understanding of fine-tuning small and medium-sized language models (SLMs/LLMs)** for **medical question answering tasks** using **parameter-efficient adaptation techniques**.\n",
        "\n",
        "By the end of this notebook, participants will:\n",
        "- Understand how domain-specific data differs from general-purpose language data\n",
        "- Learn how to adapt a pretrained language model to the medical domain using **LoRA and adapter-based fine-tuning**\n",
        "- Gain practical experience in preparing medical datasets for instruction-style training\n",
        "- Evaluate and interpret performance differences between a base model and a fine-tuned model\n",
        "\n",
        "The tutorial is designed to be **practical, reproducible, and runnable on limited GPU resources**, such as Google Colab.\n",
        "\n",
        "\n",
        "\n",
        "## Datasets Used\n",
        "\n",
        "We will work with two widely used medical QA benchmarks that reflect different reasoning styles:\n",
        "\n",
        "- **PubMedQA**  \n",
        "  - Yes / No / Maybe questions derived from PubMed abstracts  \n",
        "  - Focuses on biomedical literature understanding and reasoning  \n",
        "\n",
        "- **MedMCQA**  \n",
        "  - Multiple-choice questions sourced from medical entrance examinations  \n",
        "  - Tests clinical knowledge, factual recall, and reasoning  \n",
        "\n",
        "Using both datasets allows us to demonstrate fine-tuning for **binary-style reasoning** as well as **multi-choice clinical decision-making**.\n",
        "\n",
        "\n",
        "\n",
        "## What This Tutorial Covers\n",
        "\n",
        "This notebook walks through the **complete fine-tuning pipeline**, including:\n",
        "\n",
        "1. **Data Exploration**  \n",
        "   - Inspecting dataset structure  \n",
        "   - Understanding label formats and question styles  \n",
        "\n",
        "2. **Data Preparation**  \n",
        "   - Converting raw QA data into instruction-following prompts  \n",
        "   - Designing input–output templates suitable for LLM training  \n",
        "\n",
        "3. **Model Fine-Tuning**  \n",
        "   - Applying **4-bit Quantization** using *BitsAndBytes*.\n",
        "   - Applying **LoRA (Low-Rank Adaptation)** to reduce trainable parameters  \n",
        "   - Fine-tuning without updating the full model weights  \n",
        "\n",
        "4. **Evaluation and Analysis**  \n",
        "   - Comparing base model vs fine-tuned model accuracy  \n",
        "   - Understanding when and why fine-tuning helps  \n",
        "   - Identifying common pitfalls in evaluation  \n",
        "\n",
        "Throughout the tutorial, emphasis is placed on **conceptual clarity**, **engineering best practices**, and **debugging common issues** encountered during fine-tuning.\n",
        "\n",
        "\n",
        "\n",
        "## Target Audience\n",
        "\n",
        "This tutorial is intended for:\n",
        "\n",
        "- Graduate students and researchers who want to get into **AI, ML**\n",
        "- Practitioners interested in **domain adaptation of LLMs**\n",
        "- Participants with basic familiarity with:\n",
        "  - Python and PyTorch\n",
        "  - Hugging Face Transformers\n",
        "  - Fundamental NLP concepts  \n",
        "\n",
        "No prior experience with LoRA or adapter-based fine-tuning is assumed.\n",
        "\n",
        "\n",
        "\n",
        "## Why Parameter-Efficient Fine-Tuning?\n",
        "\n",
        "Medical and scientific datasets pose unique challenges for training large language models. In practice, these datasets are often:\n",
        "\n",
        "- **Small in size** compared to general web-scale corpora, increasing the risk of overfitting\n",
        "- **Sensitive and expensive to curate**, limiting opportunities for large-scale supervised training\n",
        "- **Trained under constrained compute environments**, such as a single consumer-grade GPU such as **Nvidia RTX Series GPUs** or cloud notebooks like **Google Colab**.\n",
        "\n",
        "Under these constraints, **full fine-tuning of all model parameters is often impractical or unnecessary**.\n",
        "\n",
        "\n",
        "\n",
        "### Limitations of Full Fine-Tuning\n",
        "\n",
        "Standard full-model fine-tuning requires:\n",
        "- Updating **billions of parameters**\n",
        "- Storing **optimizer states and gradients** for every parameter\n",
        "- Large GPU memory for activations, gradients, and optimizer buffers\n",
        "\n",
        "This leads to:\n",
        "- High VRAM consumption\n",
        "- Longer training times\n",
        "- Frequent out-of-memory (OOM) errors on limited hardware\n",
        "- Increased risk of catastrophic forgetting, where the model loses its general-language capabilities\n",
        "\n",
        "As a result, full fine-tuning is often infeasible on GPUs with limited memory, such as those available in Google Colab or institutional shared clusters.\n",
        "\n",
        "\n",
        "\n",
        "### Advantages of Parameter-Efficient Fine-Tuning (PEFT)\n",
        "\n",
        "Parameter-efficient fine-tuning methods, such as **LoRA (Low-Rank Adaptation)**, address these issues by:\n",
        "\n",
        "- **Freezing the pretrained model weights** and training only a small number of additional parameters\n",
        "- Introducing **low-rank update matrices** that capture task-specific adaptations\n",
        "- Reducing the number of trainable parameters by several orders of magnitude\n",
        "\n",
        "This results in:\n",
        "- Dramatically lower GPU memory usage\n",
        "- Faster training and iteration cycles\n",
        "- The ability to fine-tune larger models on modest hardware\n",
        "- Improved training stability on small datasets\n",
        "\n",
        "In many cases, less than **1–5% of the total parameters** are updated, while achieving performance close to full fine-tuning.\n",
        "\n",
        "\n",
        "\n",
        "### Why PEFT Works Well for Low-Resource GPUs\n",
        "\n",
        "From a systems perspective, PEFT reduces resource requirements by:\n",
        "\n",
        "- Eliminating gradient computation for frozen parameters\n",
        "- Reducing optimizer state memory (for example, Adam states are stored only for adapter parameters)\n",
        "- Lowering communication overhead in distributed or multi-GPU settings\n",
        "- Allowing higher batch sizes or longer sequence lengths within the same memory budget\n",
        "\n",
        "This makes PEFT especially suitable for:\n",
        "- Single-GPU training\n",
        "- Educational labs and tutorials\n",
        "- Rapid prototyping and experimentation\n",
        "\n",
        "\n",
        "\n",
        "### Relevance to Medical and Scientific Domains\n",
        "\n",
        "Medical language tasks often require:\n",
        "- Domain adaptation rather than learning language from scratch\n",
        "- Precise updates to specialized terminology and reasoning patterns\n",
        "- High reproducibility and controlled experimentation\n",
        "\n",
        "Parameter-efficient fine-tuning enables:\n",
        "- Domain specialization without overwriting general linguistic knowledge\n",
        "- Easier comparison between base and adapted models\n",
        "- Safe and efficient experimentation with sensitive datasets\n",
        "\n",
        "For these reasons, PEFT methods such as LoRA have become the **de facto standard** for fine-tuning LLMs in low-resource and domain-specific settings.\n",
        "\n",
        "\n",
        "\n",
        "In this tutorial, we leverage parameter-efficient fine-tuning to demonstrate how high-quality medical LLMs can be trained **without large-scale compute infrastructure**, making the approach accessible and practical.\n",
        "\n",
        "\n",
        "\n",
        "By the end of this notebook, you should be able to confidently design, fine-tune, and evaluate a medical LLM using modern, efficient adaptation techniques.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "My Contact\n",
        " - Email - jiviteshs@iiitd.ac.in\n",
        " - Linkedin - https://www.linkedin.com/in/jivitesh-sabharwal/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpfq4ii5grdI"
      },
      "source": [
        "# Part 1: Setup and Installation\n",
        "\n",
        "First, we install the required libraries for data processing and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J8Lj-SLSkKv"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS1yvvA4grdJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyL6zwcigrdJ"
      },
      "source": [
        "### Import Required Libraries\n",
        "\n",
        "We import libraries for:\n",
        "- **Data handling**: pandas, datasets (HuggingFace)\n",
        "- **Visualization**: matplotlib, seaborn\n",
        "- **Analysis**: collections.Counter for frequency counting\n",
        "- **Reproducibility**: Setting random seed ensures consistent results across runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VP1EMCASdFb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from collections import Counter\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7sK7qEVgrdK"
      },
      "source": [
        "# Part 2: Dataset Exploration\n",
        "\n",
        "### 2.1 Loading PubMedQA Dataset\n",
        "\n",
        "**PubMedQA** is a dataset for biomedical question answering where:\n",
        "- Each question is derived from a PubMed abstract\n",
        "- Answers are yes/no/maybe format\n",
        "- Includes context from research papers and expert-written explanations\n",
        "\n",
        "We use the `qiaojin/PubMedQA` source which is actively maintained and includes the \"pqa_labeled\" split with expert annotations.\n",
        "\n",
        "Source:\n",
        " - [Jin et al., 2019] Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu. **PubMedQA: A Dataset for Biomedical Research Question Answering.** Proceedings of EMNLP-IJCNLP, pages 2567–2577, 2019."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuqNSslHSgSH"
      },
      "outputs": [],
      "source": [
        "# Load PubMedQA dataset\n",
        "# Using the qiaojin/PubMedQA source which is actively maintained\n",
        "pubmedqa = load_dataset(\"qiaojin/PubMedQA\", \"pqa_labeled\", trust_remote_code=True)\n",
        "\n",
        "print(f\"PubMedQA splits: {pubmedqa}\")\n",
        "print(f\"\\nTotal examples: {len(pubmedqa['train'])}\")\n",
        "\n",
        "# Note: This dataset only has a 'train' split, we'll create our own splits later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CKEcOGtgrdK"
      },
      "source": [
        "### Examining PubMedQA Structure\n",
        "\n",
        "Let's look at a single example to understand the data structure:\n",
        "- **Question**: The medical question to answer\n",
        "- **Context**: Research abstracts providing evidence\n",
        "- **Final Decision**: The yes/no/maybe answer\n",
        "- **Long Answer**: Detailed explanation for the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fjwPVzqSpo0"
      },
      "outputs": [],
      "source": [
        "# Examine a single example\n",
        "example = pubmedqa['train'][0]\n",
        "print(\"PUBMEDQA EXAMPLE\")\n",
        "print(f\"\\nQuestion: {example['question']}\")\n",
        "context = example['context']['contexts'][0] if example['context']['contexts'] else 'N/A'\n",
        "print(f\"\\nContext (truncated): {context[:500]}...\")\n",
        "print(f\"\\nAnswer: {example['final_decision']}\")\n",
        "print(f\"\\nLong Answer: {example['long_answer'][:300]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMkhiYZaSp-o"
      },
      "outputs": [],
      "source": [
        "# Check the columns available\n",
        "print(\"Available columns in PubMedQA:\")\n",
        "print(pubmedqa['train'].column_names)\n",
        "print(\"\\nNote: 'context' is a nested dict containing 'contexts', 'labels', 'meshes', 'reasoning_required_pred', 'reasoning_free_pred'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7D6D5w7grdL"
      },
      "source": [
        "### 2.2 Loading MedMCQA Dataset\n",
        "\n",
        "**MedMCQA** is a large-scale multiple-choice question dataset from Indian medical entrance exams (AIIMS & NEET PG):\n",
        "- Contains 4 answer options (A, B, C, D)\n",
        "- Covers diverse medical subjects\n",
        "- Includes explanations for many questions\n",
        "- Pre-split into train/validation/test sets\n",
        "\n",
        "Source -\n",
        " - [Pal et al., 2022] Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu.  **MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical Domain Question Answering.** In *Proceedings of the Conference on Health, Inference, and Learning (CHIL)*, Proceedings of Machine Learning Research, Vol. 174, pages 248–260, April 2022.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "f579647b214d4f51ae5cee4c498b3081",
            "8e174588c3024e99ad964d706e3de0c5",
            "d4c36184a57c4083a5bceababcd6c3f0",
            "6e2cdbe9f4ca46a58a704ebe375e3b9a",
            "caea09b8ef174d0b9b287243add504a6",
            "725e7c7145034307b3195bc04eb3bda4",
            "caf24aa753354004b08f60f315c46cec"
          ]
        },
        "id": "WoFL2RVAToDw",
        "outputId": "42eb0b44-b27a-486f-b08f-35c307a2b640"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f579647b214d4f51ae5cee4c498b3081",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e174588c3024e99ad964d706e3de0c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/85.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4c36184a57c4083a5bceababcd6c3f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/936k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e2cdbe9f4ca46a58a704ebe375e3b9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/validation-00000-of-00001.parquet:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caea09b8ef174d0b9b287243add504a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/182822 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "725e7c7145034307b3195bc04eb3bda4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/6150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caf24aa753354004b08f60f315c46cec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/4183 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MedMCQA splits: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
            "        num_rows: 182822\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
            "        num_rows: 6150\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
            "        num_rows: 4183\n",
            "    })\n",
            "})\n",
            "\n",
            "Training examples: 182822\n",
            "Validation examples: 4183\n",
            "Test examples: 6150\n"
          ]
        }
      ],
      "source": [
        "# Load MedMCQA dataset\n",
        "medmcqa = load_dataset(\"openlifescienceai/medmcqa\")\n",
        "print(f\"MedMCQA splits: {medmcqa}\")\n",
        "print(f\"\\nTraining examples: {len(medmcqa['train'])}\")\n",
        "print(f\"Validation examples: {len(medmcqa['validation'])}\")\n",
        "print(f\"Test examples: {len(medmcqa['test'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuOVAp8xgrdL"
      },
      "source": [
        "### Examining MedMCQA Structure\n",
        "\n",
        "Each MedMCQA example contains:\n",
        "- **Question**: The medical question\n",
        "- **Options**: 4 choices (opa, opb, opc, opd)\n",
        "- **Correct Answer (cop)**: Index of the correct option (0-3)\n",
        "- **Subject & Topic**: Medical domain classification\n",
        "- **Explanation**: Reasoning for the correct answer (when available)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x4tNNSFRTp0n",
        "outputId": "157f3a55-2409-4fb6-f422-bb0b8bf42813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MEDMCQA EXAMPLE\n",
            "\n",
            "Question: All of the following are surgical options for morbid obesity except -\n",
            "\n",
            "   A) Adjustable gastric banding\n",
            "   B) Biliopancreatic diversion\n",
            "   C) Duodenal Switch\n",
            "   D) Roux en Y Duodenal By pass\n",
            "\n",
            "Correct Answer: D\n",
            "\n",
            "Subject: Surgery\n",
            "Topic: Surgical Treatment Obesity\n",
            "\n",
            " Explanation: Ans. is 'd' i.e., Roux en Y Duodenal Bypass Bariatric surgical procedures include:a. Vertical banded gastroplastyb. Adjustable gastric bandingc. Roux-en Y gastric bypass (Not - Roux-en Y Duodenal Bypass)d. Biliopancreatic diversione. Duodenal switcho The surgical treatment of morbid obesity is known...\n"
          ]
        }
      ],
      "source": [
        "# Examine a single MedMCQA example\n",
        "example = medmcqa['train'][2]\n",
        "print(\"MEDMCQA EXAMPLE\")\n",
        "print(f\"\\nQuestion: {example['question']}\")\n",
        "print(f\"\\n   A) {example['opa']}\")\n",
        "print(f\"   B) {example['opb']}\")\n",
        "print(f\"   C) {example['opc']}\")\n",
        "print(f\"   D) {example['opd']}\")\n",
        "print(f\"\\nCorrect Answer: {['A', 'B', 'C', 'D'][example['cop']]}\")\n",
        "print(f\"\\nSubject: {example['subject_name']}\")\n",
        "print(f\"Topic: {example['topic_name']}\")\n",
        "if example['exp']:\n",
        "    print(f\"\\n Explanation: {example['exp'][:300]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cIDzsWMfTr4G",
        "outputId": "de0c58d8-d801-4ad6-e27d-f3a062519573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available columns in MedMCQA:\n",
            "['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name']\n"
          ]
        }
      ],
      "source": [
        "# Check available columns\n",
        "print(\"Available columns in MedMCQA:\")\n",
        "print(medmcqa['train'].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NfeuHRRgrdM"
      },
      "source": [
        "# Part 3: Data Analysis\n",
        "\n",
        "### 3.1 Answer Distribution Analysis\n",
        "\n",
        "Understanding the distribution of answers helps us:\n",
        "- Detect class imbalance issues\n",
        "- Ensure our model doesn't simply learn to predict the most common answer\n",
        "- Verify dataset quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gp6XgGrtTtpq",
        "outputId": "2a83cfe2-a36c-4378-f52a-7dcdcb2dddda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PubMedQA Answer Distribution:\n",
            "  yes: 552 (55.2%)\n",
            "  no: 338 (33.8%)\n",
            "  maybe: 110 (11.0%)\n"
          ]
        }
      ],
      "source": [
        "# Analyze PubMedQA answer distribution\n",
        "pubmed_answers = [ex['final_decision'] for ex in pubmedqa['train']]\n",
        "pubmed_dist = Counter(pubmed_answers)\n",
        "\n",
        "print(\"PubMedQA Answer Distribution:\")\n",
        "for answer, count in pubmed_dist.items():\n",
        "    print(f\"  {answer}: {count} ({count/len(pubmed_answers)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28t63QFCgrdM"
      },
      "source": [
        "### MedMCQA Answer Distribution\n",
        "\n",
        "For multiple-choice questions, we want to see if answers are relatively balanced across A, B, C, D options. A balanced distribution suggests the dataset is well-constructed and won't bias the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV03m_YYTu-C"
      },
      "outputs": [],
      "source": [
        "# Analyze MedMCQA answer distribution\n",
        "medmcqa_answers = [ex['cop'] for ex in medmcqa['train']]\n",
        "medmcqa_dist = Counter(medmcqa_answers)\n",
        "\n",
        "print(\"MedMCQA Answer Distribution:\")\n",
        "answer_labels = ['A', 'B', 'C', 'D']\n",
        "for idx, count in sorted(medmcqa_dist.items()):\n",
        "    print(f\"  {answer_labels[idx]}: {count} ({count/len(medmcqa_answers)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLOCOx6SgrdM"
      },
      "source": [
        "### Visualizing Answer Distributions\n",
        "\n",
        "Visual comparison helps us quickly spot any imbalances in the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6qhAAkATweC"
      },
      "outputs": [],
      "source": [
        "# Visualize distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# PubMedQA\n",
        "axes[0].bar(pubmed_dist.keys(), pubmed_dist.values(), color=['green', 'red', 'gray'])\n",
        "axes[0].set_title('PubMedQA Answer Distribution')\n",
        "axes[0].set_xlabel('Answer')\n",
        "axes[0].set_ylabel('Count')\n",
        "\n",
        "# MedMCQA\n",
        "axes[1].bar(answer_labels, [medmcqa_dist[i] for i in range(4)], color='steelblue')\n",
        "axes[1].set_title('MedMCQA Answer Distribution')\n",
        "axes[1].set_xlabel('Answer')\n",
        "axes[1].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r6beRhDgrdM"
      },
      "source": [
        "### 3.2 Question Length Analysis\n",
        "\n",
        "Analyzing the distribution of question lengths is an important preprocessing step when fine-tuning language models.\n",
        "\n",
        "This analysis helps us to:\n",
        "\n",
        "- **Choose an appropriate maximum sequence length**  \n",
        "  Transformer models have a fixed context window, and setting the sequence length too high unnecessarily increases memory usage and training time. Understanding typical question lengths allows us to select a value that balances coverage and efficiency.\n",
        "\n",
        "- **Avoid truncation of critical information**  \n",
        "  Long medical questions may contain important clinical context or qualifiers. Length analysis helps ensure that truncation does not remove essential information that could negatively impact model performance.\n",
        "\n",
        "- **Identify outliers and noisy samples**  \n",
        "  Extremely long or unusually short questions may indicate formatting issues, concatenated texts, or incomplete samples. Detecting these outliers enables better data cleaning and more stable training.\n",
        "\n",
        "- **Optimize GPU memory usage**  \n",
        "  Sequence length directly affects attention computation cost. Shorter, well-chosen sequence limits allow larger batch sizes and reduce the risk of out-of-memory errors, which is especially important when working with limited GPU resources.\n",
        "\n",
        "- **Understand task complexity**  \n",
        "  Question length often correlates with reasoning complexity. Analyzing length distributions provides insight into whether the dataset primarily consists of short factual queries or longer, multi-step reasoning problems.\n",
        "\n",
        "Overall, question length analysis informs both **model configuration** and **resource-aware training decisions**, making it a critical step in practical LLM fine-tuning workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpUzj_sUgrdM"
      },
      "source": [
        "**STUDENTS NEEDS TO DO THIS TASK ON ITS OWN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxelQVORgrdM"
      },
      "source": [
        "### Task: Question Length Analysis for MedMCQA\n",
        "\n",
        "\n",
        "Your objectives are to:\n",
        "\n",
        "1. Compute the number of words in each *question* from the training split.\n",
        "2. Report basic descriptive statistics, including:\n",
        "   - Minimum question length  \n",
        "   - Maximum question length  \n",
        "   - Mean question length  \n",
        "   - Median question length  \n",
        "3. Visualize the distribution of question lengths using a histogram.\n",
        "4. Mark the median question length on the plot to better understand the central tendency.\n",
        "\n",
        "This analysis will help you understand:\n",
        "- How to choose an appropriate maximum sequence length for model fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3Cb--W-Tyh3"
      },
      "outputs": [],
      "source": [
        "# Analyze question lengths in MedMCQA\n",
        "question_lengths = [len(ex['question'].split()) for ex in medmcqa['train']]\n",
        "\n",
        "print(f\"MedMCQA Question Length Statistics:\")\n",
        "print(f\"  Min: {min(question_lengths)} words\")\n",
        "print(f\"  Max: {max(question_lengths)} words\")\n",
        "print(f\"  Mean: {sum(question_lengths)/len(question_lengths):.1f} words\")\n",
        "print(f\"  Median: {sorted(question_lengths)[len(question_lengths)//2]} words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXcoDqSKT0MC"
      },
      "outputs": [],
      "source": [
        "# Plot length distribution\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.hist(question_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
        "plt.title('MedMCQA Question Length Distribution')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.axvline(x=sorted(question_lengths)[len(question_lengths)//2], color='red', linestyle='--', label='Median')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyBq5X-KgrdN"
      },
      "source": [
        "### 3.3 Subject Distribution Analysis\n",
        "\n",
        "Understanding which medical subjects are most represented helps us:\n",
        "- Assess domain coverage\n",
        "- Identify potential biases toward specific specialties\n",
        "- Plan stratified sampling if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beTDDSJiT2YU"
      },
      "outputs": [],
      "source": [
        "# Analyze subject distribution\n",
        "subjects = [ex['subject_name'] for ex in medmcqa['train']]\n",
        "subject_dist = Counter(subjects)\n",
        "\n",
        "print(\"Top 10 Subjects in MedMCQA:\")\n",
        "for subject, count in subject_dist.most_common(10):\n",
        "    print(f\"  {subject}: {count} ({count/len(subjects)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t-CEzUgT3wO"
      },
      "outputs": [],
      "source": [
        "# Visualize top subjects\n",
        "top_subjects = subject_dist.most_common(10)\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.barh([s[0] for s in top_subjects], [s[1] for s in top_subjects], color='teal')\n",
        "plt.xlabel('Number of Questions')\n",
        "plt.title('Top 10 Medical Subjects in MedMCQA')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs0QlCc9grdN"
      },
      "source": [
        "# Part 4: Data Formatting for Instruction Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdpxufjLgrdN"
      },
      "source": [
        "### Why Do We Need an Instruction Tuning Format?\n",
        "\n",
        "Large language models are pretrained primarily using **next-token prediction** on raw text. While this enables strong language understanding, it does not automatically teach the model to:\n",
        "- Follow explicit user instructions\n",
        "- Distinguish between a task description and the input data\n",
        "- Produce structured, task-appropriate outputs\n",
        "\n",
        "Instruction tuning bridges this gap by explicitly teaching the model **how to respond when given a task description**.\n",
        "\n",
        "\n",
        "### Role of Structured Instruction Formats\n",
        "\n",
        "A structured instruction format serves several important purposes:\n",
        "\n",
        "- **Separates task intent from task input**  \n",
        "  By clearly distinguishing the instruction (what to do) from the input (the data or question), the model learns to condition its response on both.\n",
        "\n",
        "- **Aligns training data with inference-time usage**  \n",
        "  At inference, users typically prompt models using instructions. Training with an instruction format reduces distribution mismatch between training and deployment.\n",
        "\n",
        "- **Improves generalization across tasks**  \n",
        "  When models see many tasks expressed in a consistent instruction-response pattern, they learn a reusable instruction-following behavior rather than memorizing task-specific patterns.\n",
        "\n",
        "- **Encourages controllable outputs**  \n",
        "  Explicit response sections help constrain where the model should generate the answer, improving output consistency and evaluation reliability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_b7g3EFgrdN"
      },
      "source": [
        "\n",
        "### Alpaca Format\n",
        "The Alpaca instruction format is widely used because it is:\n",
        "\n",
        "- **Simple and human-readable**, making it easy to debug and modify\n",
        "- **Explicitly structured**, reducing ambiguity for the model\n",
        "- **Compatible with open-source LLMs** commonly used in fine-tuning\n",
        "- **Effective in practice**, having been shown to significantly improve instruction-following behavior even with small datasets\n",
        "Format -\n",
        "```\n",
        "### Instruction: [What to do]\n",
        "### Input: [The specific data/question]\n",
        "### Response: [The expected output]\n",
        "```\n",
        "\n",
        "This format helps the model learn to follow instructions and generate appropriate responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9FK2uINgrdN"
      },
      "source": [
        "### Task: Implement Alpaca-Style Formatting Functions for Medical QA\n",
        "\n",
        "In this task, you will write two Python functions that convert raw medical question answering examples into the **Alpaca instruction tuning format**. These formatted samples will later be used directly for fine-tuning a language model.\n",
        "\n",
        "You will work with two datasets that have different structures and reasoning requirements:\n",
        "\n",
        "- **PubMedQA**: Yes / No / Maybe questions based on biomedical research abstracts  \n",
        "- **MedMCQA**: Multiple-choice medical questions with four answer options  \n",
        "\n",
        "\n",
        "### Task 1: Format PubMedQA Examples\n",
        "\n",
        "Write a function called `format_pubmedqa_alpaca(example)` that performs the following steps:\n",
        "\n",
        "1. **Extract the context**  \n",
        "   - Combine all available context passages into a single string  \n",
        "   - If no context is present, use a default placeholder such as `\"No context provided.\"`\n",
        "\n",
        "2. **Define the instruction**  \n",
        "   - Clearly state that the model should act as a medical expert  \n",
        "   - Specify that the task is to answer a yes/no/maybe question based on the given research context\n",
        "\n",
        "3. **Create the input section**  \n",
        "   - Include both the context and the question in a readable format\n",
        "\n",
        "4. **Construct the response**  \n",
        "   - Convert the dataset label into a human-readable answer  \n",
        "   - Append a brief explanation when available\n",
        "\n",
        "5. **Return a dictionary** containing:\n",
        "   - `instruction`\n",
        "   - `input`\n",
        "   - `output`\n",
        "   - `text` formatted using:\n",
        "     ```\n",
        "     ### Instruction:\n",
        "     ### Input:\n",
        "     ### Response:\n",
        "     ```\n",
        "\n",
        "\n",
        "### Task 2: Format MedMCQA Examples\n",
        "\n",
        "Write a function called `format_medmcqa_alpaca(example)` that performs the following steps:\n",
        "\n",
        "1. **Define the instruction**  \n",
        "   - Indicate that the model should answer a multiple-choice medical question  \n",
        "   - Ask the model to select the correct option and provide a brief explanation\n",
        "\n",
        "2. **Create the input section**  \n",
        "   - Include the question text  \n",
        "   - List all four answer options labeled A, B, C, and D\n",
        "\n",
        "3. **Determine the correct answer**  \n",
        "   - Identify the correct option using the provided index  \n",
        "   - Retrieve the corresponding option text\n",
        "\n",
        "4. **Construct the response**  \n",
        "   - Clearly state the correct option and its content  \n",
        "   - Add an explanation if one is available\n",
        "\n",
        "5. **Return a dictionary** containing:\n",
        "   - `instruction`\n",
        "   - `input`\n",
        "   - `output`\n",
        "   - `text` formatted in Alpaca style\n",
        "   - Optional metadata such as subject and topic\n",
        "\n",
        "\n",
        "### Verification Step\n",
        "\n",
        "After implementing both functions:\n",
        "\n",
        "- Apply each function to a few samples from the corresponding dataset\n",
        "- Print the generated `text` field\n",
        "- Check that the instruction, input, and response sections are clearly separated and easy to read\n",
        "\n",
        "This step ensures that your formatted data is ready for instruction fine-tuning in the next part of the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrHiBWYXgrdO"
      },
      "source": [
        "#REMOVE THIS CODE FOR STUDENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JwQda4bT6rP"
      },
      "outputs": [],
      "source": [
        "def format_pubmedqa_alpaca(example):\n",
        "    \"\"\"\n",
        "    Convert PubMedQA example to Alpaca instruction format.\n",
        "    Updated for qiaojin/PubMedQA dataset structure.\n",
        "    \"\"\"\n",
        "    # Extract contexts from nested structure\n",
        "    contexts = example['context']['contexts'] if example['context']['contexts'] else []\n",
        "    context = \" \".join(contexts) if contexts else \"No context provided.\"\n",
        "\n",
        "    instruction = \"You are a medical expert. Based on the provided research context, answer the following yes/no/maybe question. Provide a brief explanation for your answer.\"\n",
        "\n",
        "    input_text = f\"Context: {context}\\n\\nQuestion: {example['question']}\"\n",
        "\n",
        "    # Create detailed response\n",
        "    answer_map = {'yes': 'Yes', 'no': 'No', 'maybe': 'Maybe'}\n",
        "    answer = answer_map.get(example['final_decision'], example['final_decision'])\n",
        "\n",
        "    long_answer = example.get('long_answer', '')\n",
        "    response = f\"{answer}. {long_answer}\" if long_answer else answer\n",
        "\n",
        "    return {\n",
        "        'instruction': instruction,\n",
        "        'input': input_text,\n",
        "        'output': response,\n",
        "        'text': f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{response}\"\n",
        "    }\n",
        "\n",
        "\n",
        "def format_medmcqa_alpaca(example):\n",
        "    \"\"\"\n",
        "    Convert MedMCQA example to Alpaca instruction format.\n",
        "    \"\"\"\n",
        "    instruction = \"You are a medical expert. Answer the following multiple-choice medical question. Choose the correct option and provide a brief explanation.\"\n",
        "\n",
        "    options = f\"A) {example['opa']}\\nB) {example['opb']}\\nC) {example['opc']}\\nD) {example['opd']}\"\n",
        "    input_text = f\"Question: {example['question']}\\n\\nOptions:\\n{options}\"\n",
        "\n",
        "    # Get correct answer\n",
        "    answer_labels = ['A', 'B', 'C', 'D']\n",
        "    correct_answer = answer_labels[example['cop']]\n",
        "    correct_option = [example['opa'], example['opb'], example['opc'], example['opd']][example['cop']]\n",
        "\n",
        "    # Build response\n",
        "    explanation = example.get('exp', '') or ''\n",
        "    if explanation:\n",
        "        response = f\"The correct answer is {correct_answer}) {correct_option}.\\n\\nExplanation: {explanation}\"\n",
        "    else:\n",
        "        response = f\"The correct answer is {correct_answer}) {correct_option}.\"\n",
        "\n",
        "    return {\n",
        "        'instruction': instruction,\n",
        "        'input': input_text,\n",
        "        'output': response,\n",
        "        'text': f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{response}\",\n",
        "        'subject': example['subject_name'],\n",
        "        'topic': example['topic_name']\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx2TG6MngrdO"
      },
      "outputs": [],
      "source": [
        "# Verify PubMedQA formatting\n",
        "print(\"===== PubMedQA: Alpaca-formatted Samples =====\\n\")\n",
        "for i in range(3):\n",
        "    formatted = format_pubmedqa_alpaca(pubmedqa['train'][i])\n",
        "    print(f\"--- Sample {i} ---\")\n",
        "    print(formatted[\"text\"])\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Verify MedMCQA formatting\n",
        "print(\"===== MedMCQA: Alpaca-formatted Samples =====\\n\")\n",
        "for i in range(3):\n",
        "    formatted = format_medmcqa_alpaca(medmcqa['train'][i])\n",
        "    print(f\"--- Sample {i} ---\")\n",
        "    print(formatted[\"text\"])\n",
        "    print(f\"\\n(Metadata) Subject: {formatted.get('subject')} | Topic: {formatted.get('topic')}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNjk7z8YgrdO"
      },
      "source": [
        "###  ChatML Format (Alternative) (optional)\n",
        "\n",
        "Chat-based large language models are typically trained to operate in a **multi-turn conversational setting**, where responses are conditioned not only on the user query but also on the conversational role and context. The **ChatML format** explicitly encodes this structure by assigning roles such as `system`, `user`, and `assistant`.\n",
        "\n",
        "\n",
        "\n",
        "### Why Use a Chat-Based Format?\n",
        "\n",
        "Using a chat-oriented format provides several advantages:\n",
        "\n",
        "- **Explicit role separation**  \n",
        "  The `system` role defines the model’s persona, expertise, and behavioral constraints, which is especially important in sensitive domains like medicine. This helps enforce consistent and safe responses.\n",
        "\n",
        "- **Closer alignment with modern LLM training**  \n",
        "  Many contemporary models are pretrained or instruction-tuned using chat-style data. Formatting training samples in ChatML reduces the mismatch between training and inference.\n",
        "\n",
        "- **Improved conversational behavior**  \n",
        "  ChatML naturally supports follow-up questions, clarifications, and multi-turn reasoning, making it suitable for interactive medical assistants.\n",
        "\n",
        "- **Clear attribution of intent and response**  \n",
        "  By separating user queries from assistant outputs, the model learns when to listen and when to generate, improving response coherence.\n",
        "\n",
        "\n",
        "\n",
        "### When ChatML Is Preferable\n",
        "\n",
        "ChatML is particularly useful when:\n",
        "- The target application is a conversational medical assistant\n",
        "- Multi-turn dialogue or context retention is important\n",
        "- System-level constraints or safety instructions must always be enforced\n",
        "\n",
        "\n",
        "\n",
        "### Relation to Alpaca Format\n",
        "\n",
        "While the Alpaca format is well-suited for single-turn instruction-following tasks, ChatML provides a more flexible structure for dialogue-based interactions. Both formats serve the same core purpose of instruction tuning, but they differ in how explicitly conversational context is represented.\n",
        "\n",
        "In practice, the choice of format depends on the **model architecture**, **training data**, and **intended deployment scenario**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUzsExwzT8ba"
      },
      "outputs": [],
      "source": [
        "def format_chatml(instruction, input_text, response):\n",
        "    \"\"\"\n",
        "    Convert to ChatML format used by many modern models.\n",
        "    \"\"\"\n",
        "    user_message = f\"{instruction}\\n\\n{input_text}\" if input_text else instruction\n",
        "\n",
        "    return {\n",
        "        'messages': [\n",
        "            {'role': 'system', 'content': 'You are a helpful medical AI assistant with expertise in clinical medicine and biomedical research.'},\n",
        "            {'role': 'user', 'content': user_message},\n",
        "            {'role': 'assistant', 'content': response}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "def format_medmcqa_chatml(example):\n",
        "    \"\"\"\n",
        "    Convert MedMCQA to ChatML format.\n",
        "    \"\"\"\n",
        "    alpaca = format_medmcqa_alpaca(example)\n",
        "    chatml = format_chatml(alpaca['instruction'], alpaca['input'], alpaca['output'])\n",
        "    return chatml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r72lyPt-grdV"
      },
      "outputs": [],
      "source": [
        "# # Create ChatML formatted dataset\n",
        "# print(\"Creating ChatML formatted dataset...\")\n",
        "\n",
        "# medmcqa_chatml = medmcqa_subset.map(\n",
        "#     format_medmcqa_chatml,\n",
        "#     remove_columns=medmcqa_subset['train'].column_names\n",
        "# )\n",
        "\n",
        "# print(\"\\nChatML Conversion Complete!\")\n",
        "# # View ChatML example\n",
        "# print(\"CHATML FORMAT EXAMPLE\")\n",
        "# example = medmcqa_chatml['train'][0]\n",
        "# for msg in example['messages']:\n",
        "#     print(f\"\\n[{msg['role'].upper()}]\")\n",
        "#     print(msg['content'][:500] if len(msg['content']) > 500 else msg['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mfd7zYGgrdV"
      },
      "source": [
        "### Converting PubMedQA to Instruction Format\n",
        "\n",
        "We apply the formatting function to all examples using HuggingFace's `.map()` method. The `remove_columns` parameter drops the original columns, keeping only our formatted versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HndZasfT90t"
      },
      "outputs": [],
      "source": [
        "# Convert PubMedQA\n",
        "print(\"Converting PubMedQA to instruction format...\")\n",
        "pubmedqa_formatted = pubmedqa.map(format_pubmedqa_alpaca, remove_columns=pubmedqa['train'].column_names)\n",
        "\n",
        "print(\"\\nPubMedQA Conversion Complete!\")\n",
        "print(f\"Columns: {pubmedqa_formatted['train'].column_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh3AmEVAT_NV"
      },
      "outputs": [],
      "source": [
        "# View a formatted example\n",
        "print(\"FORMATTED PUBMEDQA EXAMPLE\")\n",
        "print(pubmedqa_formatted['train'][0]['text'][:1500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta_oktUkgrdV"
      },
      "source": [
        "### Converting MedMCQA to Instruction Format\n",
        "\n",
        "**Important Note**: For this tutorial, we use a subset of the data to keep training time manageable:\n",
        "- 10,000 training examples (adjust `TRAIN_SIZE` based on your GPU resources)\n",
        "- 500 validation examples\n",
        "\n",
        "For production use, you'd typically use the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eww0R5yLUBEH"
      },
      "outputs": [],
      "source": [
        "# Convert MedMCQA (using a subset for speed)\n",
        "print(\"Converting MedMCQA to instruction format...\")\n",
        "\n",
        "# For the tutorial, we'll use a manageable subset\n",
        "TRAIN_SIZE = 10000 # Please change this according to your access to GPUs\n",
        "VAL_SIZE = 500\n",
        "\n",
        "medmcqa_subset = DatasetDict({\n",
        "    'train': medmcqa['train'].shuffle(seed=42).select(range(TRAIN_SIZE)),\n",
        "    'validation': medmcqa['validation'].shuffle(seed=42).select(range(VAL_SIZE))\n",
        "})\n",
        "\n",
        "medmcqa_formatted = medmcqa_subset.map(\n",
        "    format_medmcqa_alpaca,\n",
        "    remove_columns=['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'exp', 'subject_name', 'topic_name', 'choice_type']\n",
        ")\n",
        "\n",
        "print(f\"\\nMedMCQA Conversion Complete!\")\n",
        "print(f\"Training examples: {len(medmcqa_formatted['train'])}\")\n",
        "print(f\"Validation examples: {len(medmcqa_formatted['validation'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slxa2vTBgrdV"
      },
      "source": [
        "### Converting PubMedQA to Instruction Format\n",
        "\n",
        "Similar to MedMCQA, we prepare PubMedQA for training. Since PubMedQA only has a train split, we manually create train/validation splits (90/10). We also subsample to keep training tractable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsN-vcqqgrdV"
      },
      "outputs": [],
      "source": [
        "# Convert PubMedQA (using a subset for speed)\n",
        "print(\"Converting PubMedQA to instruction format...\")\n",
        "\n",
        "# PubMedQA only has a 'train' split, so we create our own train/validation split\n",
        "PUBMED_TRAIN_SIZE = 800  # Adjust based on GPU resources\n",
        "PUBMED_VAL_SIZE = 100\n",
        "\n",
        "# Shuffle and split\n",
        "pubmed_shuffled = pubmedqa['train'].shuffle(seed=42)\n",
        "pubmedqa_subset = DatasetDict({\n",
        "    'train': pubmed_shuffled.select(range(PUBMED_TRAIN_SIZE)),\n",
        "    'validation': pubmed_shuffled.select(range(PUBMED_TRAIN_SIZE, PUBMED_TRAIN_SIZE + PUBMED_VAL_SIZE))\n",
        "})\n",
        "\n",
        "pubmedqa_alpaca = pubmedqa_subset.map(\n",
        "    format_pubmedqa_alpaca,\n",
        "    remove_columns=pubmedqa_subset['train'].column_names\n",
        ")\n",
        "\n",
        "print(f\"\\nPubMedQA Conversion Complete!\")\n",
        "print(f\"Training examples: {len(pubmedqa_alpaca['train'])}\")\n",
        "print(f\"Validation examples: {len(pubmedqa_alpaca['validation'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHPZvWBYgrdV"
      },
      "outputs": [],
      "source": [
        "# View a formatted MedMCQA example\n",
        "print(\"FORMATTED MEDMCQA EXAMPLE\")\n",
        "print(medmcqa_formatted['train'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-rGbungUCXz"
      },
      "outputs": [],
      "source": [
        "# View a formatted PubMedQA example\n",
        "print(\"FORMATTED PUBMEDQA EXAMPLE\")\n",
        "print(pubmedqa_alpaca['train'][0]['text'][:1500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOJOHpvJgrdW"
      },
      "source": [
        "# Part 5: Data Quality Checks\n",
        "\n",
        "Before starting model fine-tuning, it is critical to perform basic **data quality checks** to ensure that the training data is clean, consistent, and suitable for learning.\n",
        "\n",
        "\n",
        "\n",
        "### Why Data Quality Checks Are Necessary\n",
        "\n",
        "Large language models are highly sensitive to the quality of their training data. Even small issues in the dataset can lead to:\n",
        "- Unstable training behavior\n",
        "- Poor convergence\n",
        "- Misleading evaluation results\n",
        "- Wasted computational resources\n",
        "\n",
        "Performing data quality checks helps identify and eliminate such problems early in the pipeline.\n",
        "\n",
        "\n",
        "\n",
        "### Key Checks and Their Importance\n",
        "\n",
        "- **Missing or empty fields**  \n",
        "  Samples with missing instructions, inputs, or outputs provide no learning signal and can confuse the model during training.\n",
        "\n",
        "- **Unreasonable text lengths**  \n",
        "  Extremely long samples may be truncated by the tokenizer, leading to loss of critical information, while very short samples may not contain enough context to be useful.\n",
        "\n",
        "- **Duplicate or near-duplicate samples**  \n",
        "  Excessive duplication can bias the model toward specific questions or answers and inflate performance metrics without improving generalization.\n",
        "\n",
        "- **Proper formatting**  \n",
        "  Inconsistent or malformed instruction formats can prevent the model from learning a stable instruction-following pattern.\n",
        "\n",
        "\n",
        "\n",
        "### Impact on Training and Evaluation\n",
        "\n",
        "Clean and well-structured data:\n",
        "- Improves training stability and convergence\n",
        "- Reduces unexpected runtime errors\n",
        "- Ensures that performance gains are due to learning, not data artifacts\n",
        "- Makes evaluation results more reliable and interpretable\n",
        "\n",
        "In resource-constrained environments, data quality checks are especially important because **each training step is costly**, and poorly curated data wastes limited compute.\n",
        "\n",
        "\n",
        "\n",
        "By performing these checks, we ensure that the fine-tuning process is efficient, reliable, and reproducible, setting a strong foundation for the training stages that follow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT2XnDIEUG5g"
      },
      "outputs": [],
      "source": [
        "def check_data_quality(dataset, split='train'):\n",
        "    \"\"\"\n",
        "    Perform quality checks on the formatted dataset.\n",
        "    \"\"\"\n",
        "    issues = []\n",
        "\n",
        "    # Check for empty fields\n",
        "    empty_instruction = sum(1 for ex in dataset[split] if not ex['instruction'])\n",
        "    empty_input = sum(1 for ex in dataset[split] if not ex['input'])\n",
        "    empty_output = sum(1 for ex in dataset[split] if not ex['output'])\n",
        "\n",
        "    print(f\"Quality Check Results for {split}:\")\n",
        "    print(f\"  Total examples: {len(dataset[split])}\")\n",
        "    print(f\"  Empty instructions: {empty_instruction}\")\n",
        "    print(f\"  Empty inputs: {empty_input}\")\n",
        "    print(f\"  Empty outputs: {empty_output}\")\n",
        "\n",
        "    # Check text lengths\n",
        "    text_lengths = [len(ex['text']) for ex in dataset[split]]\n",
        "    print(f\"\\n  Text length stats:\")\n",
        "    print(f\"    Min: {min(text_lengths)} chars\")\n",
        "    print(f\"    Max: {max(text_lengths)} chars\")\n",
        "    print(f\"    Mean: {sum(text_lengths)/len(text_lengths):.0f} chars\")\n",
        "\n",
        "    # Check for very long examples (might need truncation)\n",
        "    very_long = sum(1 for l in text_lengths if l > 4000)\n",
        "    print(f\"\\n  Examples > 4000 chars: {very_long} ({very_long/len(text_lengths)*100:.1f}%)\")\n",
        "\n",
        "    return text_lengths\n",
        "\n",
        "# Run quality checks\n",
        "medmcqa_lengths = check_data_quality(medmcqa_formatted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dScdY1k3grdW"
      },
      "source": [
        "### PubMedQA Quality Check\n",
        "\n",
        "We apply the same quality checks to the PubMedQA dataset to ensure data consistency before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJfzhqPdgrdW"
      },
      "outputs": [],
      "source": [
        "# Run quality checks on PubMedQA\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "pubmedqa_lengths = check_data_quality(pubmedqa_alpaca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWeD48JcgrdW"
      },
      "source": [
        "### Duplicate Detection\n",
        "\n",
        "Duplicates can cause overfitting, so we check for exact duplicates in the formatted text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ovK8XYUI8o"
      },
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "def check_duplicates(dataset, split='train'):\n",
        "    texts = [ex['text'] for ex in dataset[split]]\n",
        "    unique_texts = set(texts)\n",
        "    duplicates = len(texts) - len(unique_texts)\n",
        "    print(f\"Duplicate check for {split}:\")\n",
        "    print(f\"  Total: {len(texts)}\")\n",
        "    print(f\"  Unique: {len(unique_texts)}\")\n",
        "    print(f\"  Duplicates: {duplicates} ({duplicates/len(texts)*100:.2f}%)\")\n",
        "    return duplicates\n",
        "\n",
        "check_duplicates(medmcqa_formatted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfvAOv0IgrdW"
      },
      "outputs": [],
      "source": [
        "# Check for duplicates in PubMedQA\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "check_duplicates(pubmedqa_alpaca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCMcbBNQgrdW"
      },
      "source": [
        "### Saving Prepared Data\n",
        "\n",
        "We save the formatted datasets to disk so they can be:\n",
        "- Reused in future sessions without reformatting\n",
        "- Shared with team members\n",
        "- Used in the training notebook\n",
        "\n",
        "The `.save_to_disk()` method preserves the entire dataset structure efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vGHVlZ6ULEs"
      },
      "outputs": [],
      "source": [
        "# Save to disk for use in the next notebook\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('prepared_data', exist_ok=True)\n",
        "\n",
        "# Save MedMCQA formatted dataset (Alpaca format)\n",
        "medmcqa_formatted.save_to_disk('prepared_data/medmcqa_alpaca')\n",
        "print(\"Saved: prepared_data/medmcqa_alpaca\")\n",
        "\n",
        "# Save MedMCQA ChatML format\n",
        "# medmcqa_chatml.save_to_disk('prepared_data/medmcqa_chatml')\n",
        "# print(\"Saved: prepared_data/medmcqa_chatml\")\n",
        "\n",
        "# Save PubMedQA formatted dataset\n",
        "pubmedqa_formatted.save_to_disk('prepared_data/pubmedqa_alpaca')\n",
        "print(\"Saved: prepared_data/pubmedqa_alpaca\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX6_g24QUMsv"
      },
      "outputs": [],
      "source": [
        "!ls -la prepared_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZZXjp5wUPzv"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR8mPyX-grdX"
      },
      "source": [
        "\n",
        "# PART 6: Model Fine-Tuning\n",
        "\n",
        "Environment Setup for Training\n",
        "\n",
        "## Checking GPU Availability\n",
        "\n",
        "First, we verify that CUDA is available and check GPU specifications. This is crucial for:\n",
        "- Ensuring we can run training\n",
        "- Understanding memory constraints\n",
        "- Optimizing batch sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-dt6AmIgrdX"
      },
      "source": [
        "### Installing Training Libraries\n",
        "\n",
        "Key libraries:\n",
        "- **transformers**: HuggingFace library for LLMs\n",
        "- **accelerate**: Distributed training utilities\n",
        "- **peft**: Parameter-Efficient Fine-Tuning (includes LoRA)\n",
        "- **bitsandbytes**: 4-bit/8-bit quantization for memory efficiency\n",
        "- **trl**: Transformer Reinforcement Learning (includes SFTTrainer)\n",
        "- **scipy**: Scientific computing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph2_BPUkUTVz",
        "outputId": "74c949db-6879-484d-c4fa-d6d30456c1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers accelerate peft bitsandbytes trl wandb scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H1SRHPTUVSR"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        "    TaskType,\n",
        ")\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from datasets import load_from_disk, load_dataset\n",
        "import os\n",
        "\n",
        "# Check CUDA\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYpyeulhgrdX"
      },
      "source": [
        "### Loading Training Data\n",
        "\n",
        "We try to load the prepared dataset from Part 1. If it doesn't exist (e.g., running this notebook standalone), we create it inline with the same formatting logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxFfJYfQUdiG"
      },
      "outputs": [],
      "source": [
        "# Try to load from disk (if you ran Notebook 1)\n",
        "# Otherwise, we'll prepare it inline\n",
        "\n",
        "try:\n",
        "    dataset = load_from_disk('prepared_data/medmcqa_alpaca')\n",
        "    print(\"Loaded dataset from prepared_data/medmcqa_alpaca\")\n",
        "except:\n",
        "    print(\"Prepared dataset not found. Creating it now...\")\n",
        "\n",
        "    # Load and prepare MedMCQA\n",
        "    from datasets import DatasetDict\n",
        "\n",
        "    raw_dataset = load_dataset(\"openlifescienceai/medmcqa\")\n",
        "\n",
        "    def format_medmcqa(example):\n",
        "        instruction = \"You are a medical expert. Answer the following multiple-choice medical question. Choose the correct option and provide a brief explanation.\"\n",
        "        options = f\"A) {example['opa']}\\nB) {example['opb']}\\nC) {example['opc']}\\nD) {example['opd']}\"\n",
        "        input_text = f\"Question: {example['question']}\\n\\nOptions:\\n{options}\"\n",
        "\n",
        "        answer_labels = ['A', 'B', 'C', 'D']\n",
        "        correct_answer = answer_labels[example['cop']]\n",
        "        correct_option = [example['opa'], example['opb'], example['opc'], example['opd']][example['cop']]\n",
        "\n",
        "        explanation = example.get('exp', '') or ''\n",
        "        if explanation:\n",
        "            response = f\"The correct answer is {correct_answer}) {correct_option}.\\n\\nExplanation: {explanation}\"\n",
        "        else:\n",
        "            response = f\"The correct answer is {correct_answer}) {correct_option}.\"\n",
        "\n",
        "        return {\n",
        "            'text': f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{response}\"\n",
        "        }\n",
        "\n",
        "    # Use subset for training\n",
        "    dataset = DatasetDict({\n",
        "        'train': raw_dataset['train'].shuffle(seed=42).select(range(5000)).map(format_medmcqa),\n",
        "        'validation': raw_dataset['validation'].shuffle(seed=42).select(range(500)).map(format_medmcqa)\n",
        "    })\n",
        "\n",
        "    print(\"Dataset prepared!\")\n",
        "\n",
        "print(f\"\\nTraining examples: {len(dataset['train'])}\")\n",
        "print(f\"Validation examples: {len(dataset['validation'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKx1YJTJgrdY"
      },
      "source": [
        "### Loading PubMedQA Training Data\n",
        "\n",
        "We load the prepared PubMedQA dataset similarly. If the pre-processed version doesn't exist, we create it inline using the same formatting logic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soY-g790grdY"
      },
      "source": [
        "# Part 7: Training Configuration\n",
        "\n",
        "### Understanding the Parameters\n",
        "\n",
        "**Model Selection**:\n",
        "- We use small models (1B-3B parameters) suitable for limited GPU resources\n",
        "- Try `unsloth/Llama-3.2-1B` or `Qwen/Qwen3-0.6B` or `Qwen/Qwen2.5-0.5B-Instruct`\n",
        "\n",
        "**LoRA Parameters**:\n",
        "- **r (rank)**: Number of trainable dimensions (8 is a good starting point)\n",
        "- **alpha**: Scaling factor (typically 2x rank = 16)\n",
        "- **dropout**: Regularization to prevent overfitting (0.05 = 5%)\n",
        "\n",
        "**Training Parameters**:\n",
        "- **MAX_SEQ_LENGTH**: Maximum input length (1024 tokens)\n",
        "- **BATCH_SIZE**: Examples per GPU (4 for limited memory)\n",
        "- **GRADIENT_ACCUMULATION**: Simulate larger batches (effective batch = 4 × 4 = 16)\n",
        "- **LEARNING_RATE**: Step size for optimization (2e-4 is typical for LoRA)\n",
        "- **MAX_STEPS**: Total training steps (200 for quick demo; increase for better results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h_Icg6zgrdY"
      },
      "outputs": [],
      "source": [
        "# Load PubMedQA dataset for training\n",
        "try:\n",
        "    pubmedqa_dataset = load_from_disk('prepared_data/pubmedqa_alpaca')\n",
        "    print(\"Loaded PubMedQA dataset from prepared_data/pubmedqa_alpaca\")\n",
        "\n",
        "    # Check if validation split exists, if not create it from train\n",
        "    if 'validation' not in pubmedqa_dataset:\n",
        "        print(\"No validation split found, creating one from train data...\")\n",
        "        shuffled = pubmedqa_dataset['train'].shuffle(seed=42)\n",
        "        train_size = int(len(shuffled) * 0.9)\n",
        "        pubmedqa_dataset = DatasetDict({\n",
        "            'train': shuffled.select(range(train_size)),\n",
        "            'validation': shuffled.select(range(train_size, len(shuffled)))\n",
        "        })\n",
        "except:\n",
        "    print(\"Prepared PubMedQA dataset not found. Creating it now...\")\n",
        "\n",
        "    from datasets import DatasetDict\n",
        "\n",
        "    raw_pubmedqa = load_dataset(\"qiaojin/PubMedQA\", \"pqa_labeled\", trust_remote_code=True)\n",
        "\n",
        "    def format_pubmedqa(example):\n",
        "        # Extract contexts from nested structure\n",
        "        contexts = example['context']['contexts'] if example['context']['contexts'] else []\n",
        "        context = \" \".join(contexts) if contexts else \"No context provided.\"\n",
        "\n",
        "        instruction = \"You are a medical expert. Based on the provided research context, answer the following yes/no/maybe question. Provide a brief explanation for your answer.\"\n",
        "        input_text = f\"Context: {context}\\n\\nQuestion: {example['question']}\"\n",
        "\n",
        "        answer_map = {'yes': 'Yes', 'no': 'No', 'maybe': 'Maybe'}\n",
        "        answer = answer_map.get(example['final_decision'], example['final_decision'])\n",
        "        long_answer = example.get('long_answer', '')\n",
        "        response = f\"{answer}. {long_answer}\" if long_answer else answer\n",
        "\n",
        "        return {\n",
        "            'text': f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{response}\"\n",
        "        }\n",
        "\n",
        "    # Split PubMedQA (only has train split) into train/validation\n",
        "    shuffled = raw_pubmedqa['train'].shuffle(seed=42)\n",
        "    train_size = int(len(shuffled) * 0.9)\n",
        "\n",
        "    pubmedqa_dataset = DatasetDict({\n",
        "        'train': shuffled.select(range(train_size)).map(format_pubmedqa),\n",
        "        'validation': shuffled.select(range(train_size, len(shuffled))).map(format_pubmedqa)\n",
        "    })\n",
        "\n",
        "    print(\"PubMedQA dataset prepared!\")\n",
        "\n",
        "print(f\"\\nPubMedQA Training examples: {len(pubmedqa_dataset['train'])}\")\n",
        "print(f\"PubMedQA Validation examples: {len(pubmedqa_dataset['validation'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu5ma7_jUXQ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Options: \"unsloth/Llama-3.2-1B\", \"Qwen/Qwen3-0.6B\" - Please try out with other small LLMs\n",
        "MODEL_ID = \"unsloth/Llama-3.2-1B\"\n",
        "\n",
        "# LoRA Configuration\n",
        "LORA_R = 8              # LoRA rank (higher = more parameters, better quality)\n",
        "LORA_ALPHA = 16          # LoRA alpha (scaling factor, typically 2x rank)\n",
        "LORA_DROPOUT = 0.05      # Dropout for regularization\n",
        "\n",
        "# Training Configuration\n",
        "MAX_SEQ_LENGTH = 1024    # Maximum sequence length\n",
        "BATCH_SIZE = 4           # Per-device batch size\n",
        "GRADIENT_ACCUMULATION = 4  # Effective batch = BATCH_SIZE * GRADIENT_ACCUMULATION\n",
        "LEARNING_RATE = 2e-4     # Learning rate\n",
        "NUM_EPOCHS = 1           # Number of training epochs\n",
        "MAX_STEPS = 10          # Max steps (overrides epochs for quick demo)\n",
        "\n",
        "# Output\n",
        "OUTPUT_DIR = \"./medical_llm_finetuned\"\n",
        "LOGGING_STEPS = 10\n",
        "\n",
        "print(\"Configuration loaded!\")\n",
        "print(f\"\\nModel: {MODEL_ID}\")\n",
        "print(f\"LoRA rank: {LORA_R}, alpha: {LORA_ALPHA}\")\n",
        "print(f\"Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION}\")\n",
        "print(f\"Max steps: {MAX_STEPS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma_l33GVgrdY"
      },
      "source": [
        "# Part 8: Model Quantization Setup\n",
        "\n",
        "## What is Quantization?\n",
        "\n",
        "Most language models are trained and stored using **floating point numbers** (often FP32 or FP16/BF16). These formats are accurate, but they are also memory hungry.\n",
        "\n",
        "**Quantization** is a compression technique that represents numbers using **fewer bits** (for example 8-bit or 4-bit). Fewer bits means less memory and often faster inference, at the cost of a small approximation error.\n",
        "\n",
        "In practice, quantization is one of the main reasons we can run and fine-tune multi-billion parameter models on limited hardware.\n",
        "\n",
        "\n",
        "## Why Quantization is Needed\n",
        "\n",
        "Large language models have two major memory costs:\n",
        "\n",
        "1. **Model weights** (parameters)\n",
        "2. **Runtime memory** during inference or training (activations, KV cache, optimizer states)\n",
        "\n",
        "Even if you have enough RAM to download a model, you may not have enough **GPU VRAM** to load it and run it.\n",
        "\n",
        "Quantization helps because it:\n",
        "\n",
        "- **Reduces VRAM usage**, making bigger models usable on consumer GPUs\n",
        "- **Speeds up loading** and sometimes inference throughput\n",
        "- Enables workflows like **QLoRA**, where the base model is quantized and only small adapters are trained\n",
        "\n",
        "A quick rule of thumb for weight storage:\n",
        "\n",
        "- FP32: 4 bytes per parameter  \n",
        "- FP16/BF16: 2 bytes per parameter  \n",
        "- INT8: 1 byte per parameter  \n",
        "- 4-bit: 0.5 bytes per parameter  \n",
        "\n",
        "So compared to FP32, 4-bit is roughly an **8× reduction** in weight memory.\n",
        "\n",
        "\n",
        "## Where Quantization is Applied\n",
        "\n",
        "Quantization can be applied to multiple parts of a model. In most LLM workflows, we quantize **weights**, and keep compute in higher precision for stability.\n",
        "\n",
        "| What can be quantized | What it means | Common in LLM practice |\n",
        "|---|---|---|\n",
        "| **Weights** | Stored model parameters | Yes (most common) |\n",
        "| **Activations** | Intermediate values during forward pass | Sometimes (more complex) |\n",
        "| **Gradients** | Backprop values during training | Rare |\n",
        "| **Optimizer states** | Adam moments and buffers | Rare (except special optimizers) |\n",
        "\n",
        "In LoRA and QLoRA settings, the usual pattern is:\n",
        "\n",
        "- Base model weights: quantized (4-bit or 8-bit)\n",
        "- Compute (matmuls): FP16 or BF16\n",
        "- Trainable adapters (LoRA): FP16 or BF16\n",
        "\n",
        "\n",
        "## Overview: Levels of Quantization and Memory Savings\n",
        "\n",
        "Below is a practical overview of precision choices and typical memory savings for *weights*:\n",
        "\n",
        "| Precision | Bits | Approx bytes per parameter | Approx weight memory reduction vs FP32 |\n",
        "|---|---:|---:|---:|\n",
        "| FP32 | 32 | 4.0 | 1× |\n",
        "| FP16 / BF16 | 16 | 2.0 | 2× |\n",
        "| INT8 | 8 | 1.0 | 4× |\n",
        "| 4-bit (FP4 / NF4) | 4 | 0.5 | 8× |\n",
        "\n",
        "Notes:\n",
        "- These numbers refer to **weight storage**, not total training memory.\n",
        "- Total memory also includes activations, KV cache, and optimizer states.\n",
        "\n",
        "\n",
        "## How Quantization is Done (High-Level)\n",
        "\n",
        "Quantization typically involves:\n",
        "\n",
        "1. **Choosing a target precision** (8-bit, 4-bit)\n",
        "2. **Mapping continuous float values to a smaller set of discrete values**\n",
        "3. Storing **scale factors** (and sometimes zero-points) so values can be approximately reconstructed\n",
        "4. Performing compute in higher precision when needed (for stability)\n",
        "\n",
        "There are two broad strategies:\n",
        "\n",
        "- **Post-Training Quantization (PTQ)**: quantize after training, no retraining required  \n",
        "- **Quantization-Aware Training (QAT)**: quantization effects are simulated during training so the model adapts\n",
        "\n",
        "For QLoRA and bitsandbytes 4-bit loading, the common approach is effectively PTQ-like weight quantization, combined with higher precision compute.\n",
        "\n",
        "\n",
        "## Helpful Visual Intuition (Images)\n",
        "\n",
        "### A simple view of scaling quantization\n",
        "<img src=\"https://cdn-uploads.huggingface.co/production/uploads/6141a88b3a0ec78603c9e784/rYKKk1_EHID9zqRK1cbda.png\" width=\"60%\" alt=\"Scaling quantization diagram\">\n",
        "\n",
        "### Example showing quantize then de-quantize\n",
        "<img src=\"https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/quant-freeze.png\" width = \"60%\" alt = \"Quantize and de-quantize example\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3ND_MrGgrdY"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "<blockquote class=\"twitter-tweet\">\n",
        "  <p lang=\"en\" dir=\"ltr\">\n",
        "    Our analysis is extensive, spanning 5 models (BLOOM, BLOOM, Pythia, GPT-2, OPT),\n",
        "    from 3 to 8-bit precision, and from 19M to 66B scale.\n",
        "    We find the same result again and again:\n",
        "    bit-level scaling improves from 16-bit to 4-bit precision but reverses at 3-bit precision.\n",
        "    <a href=\"https://t.co/Zny7OjfoOb\">pic.twitter.com/Zny7OjfoOb</a>\n",
        "  </p>\n",
        "  &mdash; Tim Dettmers (@Tim_Dettmers)\n",
        "  <a href=\"https://twitter.com/Tim_Dettmers/status/1605209177919750147\">\n",
        "    December 20, 2022\n",
        "  </a>\n",
        "</blockquote>\n",
        "\n",
        "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STQlwYEygrdY"
      },
      "source": [
        "- The figure compares zero-shot accuracy of multiple transformer models under a fixed memory budget, showing that using lower precision allows models to allocate memory to more parameters rather than higher numerical precision.\n",
        "\n",
        "- Across all model families and scales, 4-bit quantization consistently achieves the highest accuracy for the same total model memory, outperforming 8-bit and 16-bit models, while 3-bit precision leads to instability and accuracy degradation.\n",
        "\n",
        "- This demonstrates a bit-level scaling law: reducing precision down to 4 bits improves performance by enabling larger models, but pushing precision lower than 4 bits causes quantization noise to dominate and hurt generalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvy9uC9VgrdY"
      },
      "source": [
        "## 4-Bit Quantization with NF4\n",
        "\n",
        "### Why 4-bit?\n",
        "\n",
        "4-bit quantization reduces weight memory dramatically (roughly 8× compared to FP32). This is what makes it feasible to:\n",
        "\n",
        "- Load bigger models on GPUs with 8 to 16 GB VRAM\n",
        "- Fine tune billion parameter models in Colab like environments\n",
        "- Run experiments without requiring large multi-GPU setups\n",
        "\n",
        "However, **naive** 4-bit quantization can noticeably hurt quality. That is why NF4 is used.\n",
        "\n",
        "\n",
        "### What is NF4?\n",
        "\n",
        "**NF4 (NormalFloat4)** is a 4-bit data type designed for weights that are approximately **normally distributed**, which is commonly observed in transformer weights.\n",
        "\n",
        "Key idea:\n",
        "- Instead of uniform spacing between quantization levels, NF4 uses a distribution-aware spacing that better matches typical weight statistics.\n",
        "\n",
        "Practical outcome:\n",
        "- NF4 often preserves quality better than plain uniform 4-bit quantization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGVsLhqqgrdZ"
      },
      "source": [
        "<img src=\"https://i.ibb.co/cXbSY4Vy/Screenshot-2026-01-04-165841.png\" alt=\"NF4 Quantization\" border=\"0\" width='1000'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjyRDqpOgrdZ"
      },
      "source": [
        "\n",
        "\n",
        "### Double Quantization\n",
        "\n",
        "**Double quantization** saves additional memory by quantizing the *quantization constants* (for example, per-block scale values).\n",
        "\n",
        "Intuition:\n",
        "- Normal quantization stores some scaling metadata in higher precision.\n",
        "- Double quantization compresses that metadata too.\n",
        "\n",
        "This gives small but useful extra savings, especially at scale.\n",
        "\n",
        "\n",
        "### Compute dtype: Why BF16?\n",
        "\n",
        "Even if weights are stored as 4-bit values, we usually do computations in a higher precision dtype.\n",
        "\n",
        "- **BF16** often behaves better than FP16 for some models, because BF16 has a wider exponent range.\n",
        "- This can reduce instability in attention and matmul operations.\n",
        "\n",
        "So the common pattern is:\n",
        "- store weights in 4-bit\n",
        "- compute in BF16 (or FP16)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## References (Blog Links)\n",
        "\n",
        "- Beginner guide on quantization for LLMs: https://simplismart.ai/blog/a-beginners-guide-to-quantization-for-large-language-models-llms  \n",
        "- Quantization overview with practical intuition: https://www.maartengrootendorst.com/blog/quantization/  \n",
        "- Hugging Face: Quantization introduction and examples: https://huggingface.co/blog/merve/quantization  \n",
        "- Hugging Face: 4-bit bitsandbytes and QLoRA overview: https://huggingface.co/blog/4bit-transformers-bitsandbytes  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k43FQh3-Ufob"
      },
      "outputs": [],
      "source": [
        "# Configure 4-bit quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                     # Loads model weights in 4-bit format, which is a large memory reduction relative to FP16 or FP32.\n",
        "    bnb_4bit_quant_type=\"nf4\",            # Uses NormalFloat4, a 4-bit quantization scheme designed to better preserve quality for normally distributed weights.\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16, # Keeps computations in BF16 rather than 4-bit, which improves numerical stability.\n",
        "    bnb_4bit_use_double_quant=True,       #  nested quantization to reduce overhead from scaling constants.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jc4enI1grdZ"
      },
      "source": [
        "### Loading the Tokenizer\n",
        "\n",
        "The **tokenizer** converts text to token IDs that the model can process:\n",
        "- We load the tokenizer matching our model\n",
        "- Set padding token (needed for batch processing)\n",
        "- Use right-side padding (required for causal language modeling training) so that you can process variable sequence length samples in a batch simultaneously.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMWTkzXCgrdZ"
      },
      "source": [
        "## Task: Load and Configure a Tokenizer for LLM Training\n",
        "\n",
        "Write code to:\n",
        "\n",
        "1. Load a tokenizer using `AutoTokenizer.from_pretrained` for a given `MODEL_ID`\n",
        "2. Enable `trust_remote_code`\n",
        "3. Check whether a padding token exists\n",
        "4. If missing, set the padding token to the end-of-sequence token\n",
        "5. Configure the tokenizer to use **right-side padding**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI7EN_wXgrdZ"
      },
      "source": [
        "REMOVE THIS CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK3CPhzjUjC1"
      },
      "outputs": [],
      "source": [
        "# Load tokenizer\n",
        "print(f\"Loading tokenizer for {MODEL_ID}...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# Set padding token (required for training)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "tokenizer.padding_side = \"right\"  # Required for training\n",
        "\n",
        "print(f\"Tokenizer loaded!\")\n",
        "print(f\"Vocab size: {tokenizer.vocab_size}\")\n",
        "print(f\"Pad token: {tokenizer.pad_token}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxy_mU2AgrdZ"
      },
      "source": [
        "### Loading the Base Model\n",
        "\n",
        "We load the model with:\n",
        "- **4-bit quantization**: Reduces memory from ~4GB to ~1GB for a 1B model\n",
        "- **device_map=\"auto\"**: Automatically places model on GPU\n",
        "- **gradient_checkpointing**: Trades computation for memory (allows larger batches)\n",
        "\n",
        "This may take 1-2 minutes to download and quantize the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyn3YZLJgrdZ"
      },
      "source": [
        "## Task: Load a Quantized Causal Language Model\n",
        "\n",
        "Write code to:\n",
        "\n",
        "1. Load a causal language model (`MODEL_ID`) using `AutoModelForCausalLM.from_pretrained`\n",
        "2. Apply a **4-bit quantization configuration** (`bnb_config`)\n",
        "3. Use automatic device placement with `device_map=\"auto\"`\n",
        "4. Enable `trust_remote_code`\n",
        "5. Set the model compute dtype to `bfloat16`\n",
        "6. Enable **gradient checkpointing** for memory efficiency\n",
        "7. Print the model type and total number of parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y6zj-OPUkXx"
      },
      "outputs": [],
      "source": [
        "# Load model with quantization\n",
        "print(f\"Loading {MODEL_ID} with 4-bit quantization...\")\n",
        "print(\"This may take 1-2 minutes...\\n\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",           # Automatically place on GPU\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "# Enable gradient checkpointing for memory efficiency\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "print(f\"\\nModel loaded!\")\n",
        "print(f\"Model type: {model.config.model_type}\")\n",
        "print(f\"Parameters: {model.num_parameters() / 1e9:.2f}B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSYbV4aWUl0o"
      },
      "outputs": [],
      "source": [
        "# Check memory usage\n",
        "if torch.cuda.is_available():\n",
        "    memory_used = torch.cuda.memory_allocated() / 1e9\n",
        "    memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU Memory: {memory_used:.1f} GB / {memory_total:.1f} GB ({memory_used/memory_total*100:.0f}% used)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zguqh0tvgrda"
      },
      "source": [
        "# Part 9: LoRA Configuration\n",
        "\n",
        "### Preparing for K-bit Training\n",
        "\n",
        "This function prepares the quantized model for training by:\n",
        "- Freezing base model parameters\n",
        "- Enabling gradient checkpointing\n",
        "- Setting up gradients for LoRA adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpTiO9wsUnTW"
      },
      "outputs": [],
      "source": [
        "# Prepare model for k-bit training\n",
        "model = prepare_model_for_kbit_training(\n",
        "    model,\n",
        "    use_gradient_checkpointing=True,\n",
        ")\n",
        "\n",
        "print(\"Model prepared for training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnpTd_aCgrda"
      },
      "source": [
        "#### Why `prepare_model_for_kbit_training` Is Needed ?\n",
        "\n",
        "When fine-tuning a model in 8-bit or 4-bit precision, this step ensures training remains stable and memory efficient.\n",
        "\n",
        "- Freezes quantized weights so low-precision parameters are not directly updated, avoiding numerical instability.\n",
        "- Keeps sensitive layers like LayerNorm in full precision, improving training stability.\n",
        "- Enables correct gradient flow to trainable components such as LoRA adapters.\n",
        "- Supports gradient checkpointing, reducing GPU memory usage by recomputing activations during backpropagation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug_htLaMgrda"
      },
      "source": [
        "## LoRA: Low-Rank Adaptation\n",
        "\n",
        "LoRA (Low-Rank Adaptation) is a parameter-efficient fine-tuning (PEFT) technique for large pre-trained models like LLMs and diffusion models. Instead of fine-tuning all the parameters in a massive model, LoRA freezes the pre-trained model weights and injects trainable rank-decomposition matrices into each layer of the Transformer architecture. This drastically reduces the number of trainable parameters for downstream tasks.\n",
        "\n",
        "### The Core Idea\n",
        "\n",
        "- The hypothesis behind LoRA is that the change in weights during model adaptation has a low \"intrinsic rank\".\n",
        "- This means the update matrix  $\\Delta W$ for a pre-trained weight matrix $W$ can be represented by the product of two much smaller matrices,$A$ and $B$.\n",
        "\n",
        "- If $W$ has dimensions $d \\times k$, instead of learning the full $d \\times k$ update, LoRA learns $A$ (of dimension $d \\times r$) and $B$ (of dimension $r \\times k$), where the rank $r$ is much smaller than $d$ or $k$.\n",
        "\n",
        "### How it Works\n",
        "\n",
        "- During fine-tuning, the original weight matrix $W$ is kept frozen.\n",
        "- The new trainable matrices $A$ and $B$ are initialized (usually $A$ with random Gaussian noise and $B$ with zeros, so the initial update is zero).\n",
        "- In the forward pass, the input $x$ is multiplied by both $W$ and the product $BA$. The outputs are then summed to produce the final activations.\n",
        "- The forward pass equation becomes:\n",
        "\n",
        "    $h = Wx + \\Delta Wx = Wx + BAx$\n",
        "\n",
        "\n",
        "At inference time, the learned low-rank matrices $BA$ can be explicitly merged with the original weights $W$ ($W_{new} = W + BA$), resulting in no additional inference latency compared to the original model.\n",
        "\n",
        "### Key Benefits\n",
        "\n",
        "* **Parameter Efficiency:** Reduces the number of trainable parameters by up to 10,000x, making it possible to fine-tune huge models on consumer hardware.\n",
        "* **Memory Usage:** Significantly lowers GPU memory requirements since gradients are only needed for the small  and  matrices.\n",
        "* **No Inference Latency:** The trained weights can be merged back into the base model, ensuring the final model is just as fast as the original.\n",
        "* **Easy Task Switching:** You can train multiple LoRA adapters for different tasks and switch between them by simply swapping the small  and  matrices, without reloading the entire base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjSJA10Kgrda"
      },
      "source": [
        "## Understanding LoRA\n",
        "\n",
        "**LoRA (Low-Rank Adaptation)** is a parameter-efficient fine-tuning method:\n",
        "\n",
        "Instead of updating all model weights, LoRA:\n",
        "1. Freezes the original model weights\n",
        "2. Injects small \"adapter\" matrices into specific layers\n",
        "3. Only trains these adapters (typically <1% of total parameters)\n",
        "\n",
        "## Which Weight Matrices Should Be Targeted for LoRA?\n",
        "\n",
        "- LoRA is most effective when applied to weight matrices that control **information flow and representation mixing** inside a Transformer.\n",
        "- In practice, this means targeting **linear projection layers** rather than embeddings or normalization layers.\n",
        "\n",
        "\n",
        "\n",
        "### Primary Targets\n",
        "\n",
        "#### 1. Attention Projection Matrices\n",
        "These are the most important and commonly used LoRA targets.\n",
        "\n",
        "- **Query projection (`q_proj`)**\n",
        "- **Key projection (`k_proj`)**\n",
        "- **Value projection (`v_proj`)**\n",
        "- **Output projection (`o_proj`)**\n",
        "\n",
        "**Why target them**\n",
        "- Attention layers dominate model capacity\n",
        "- Task adaptation often requires changing how tokens attend to each other\n",
        "- High performance gains with minimal parameters\n",
        "\n",
        "This achieves similar performance to full fine-tuning with:\n",
        "- 100x fewer trainable parameters\n",
        "- Much less memory required\n",
        "- Faster training\n",
        "- Easier to share (adapter files are tiny ~10-50MB vs full models ~5GB+)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dug9RMnuUpEq"
      },
      "outputs": [],
      "source": [
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=LORA_R,                    # Rank of the update matrices\n",
        "    lora_alpha=LORA_ALPHA,       # Scaling factor\n",
        "    lora_dropout=LORA_DROPOUT,   # Dropout probability\n",
        "    bias=\"none\",                 # Don't train biases\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    target_modules=[             # Which layers to apply LoRA to\n",
        "        \"q_proj\",   # Query projection\n",
        "        \"k_proj\",   # Key projection\n",
        "        \"v_proj\",   # Value projection\n",
        "        \"o_proj\",   # Output projection\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"LoRA configuration ready!\")\n",
        "print(f\"\\nLoRA Settings:\")\n",
        "print(f\"Rank (r): {LORA_R}\")\n",
        "print(f\"Alpha: {LORA_ALPHA}\")\n",
        "print(f\"Effective scaling: {LORA_ALPHA/LORA_R}\")\n",
        "print(f\"Target modules: {lora_config.target_modules}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2m0LDyUgrda"
      },
      "source": [
        "### Applying LoRA to the Model\n",
        "\n",
        "This wraps our model with LoRA adapters. We then check how many parameters are trainable - you should see only ~1% are being trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxKzeH7kUqhw"
      },
      "outputs": [],
      "source": [
        "# Apply LoRA to model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Print trainable parameters\n",
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "\n",
        "    print(f\"\\n Parameter Statistics:\")\n",
        "    print(f\"Total parameters: {all_params:,} ({all_params/1e6:.1f}M)\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/1e6:.1f}M)\")\n",
        "    print(f\"Trainable %: {100 * trainable_params / all_params:.2f}%\")\n",
        "\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9lyFutVgrda"
      },
      "source": [
        "# Part 10: Training Configuration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Z7YvTEgrda"
      },
      "source": [
        "## `SFTTrainer` Pipeline: A Comprehensive Guide\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The **`SFTTrainer`** (Supervised Fine-Tuning Trainer) is part of the TRL (Transformer Reinforcement Learning) library developed by Hugging Face. It provides a streamlined interface for fine-tuning language models using supervised learning techniques.\n",
        "\n",
        "\n",
        "\n",
        "## What is `SFTTrainer`?\n",
        "\n",
        "`SFTTrainer` is a specialized trainer class that wraps around the standard Hugging Face `Trainer` class, specifically optimized for **Supervised Fine-Tuning (SFT)** of language models. It simplifies the process of adapting pre-trained language models to specific downstream tasks by training them on pairs of input and output sequences.\n",
        "\n",
        "### Core Concept\n",
        "\n",
        "The SFT method trains a model to minimize the **negative log-likelihood (NLL)** of the target sequence, conditioning on the input:\n",
        "\n",
        "$$\\mathcal{L}_{\\text{SFT}}(\\theta) = - \\sum_{t=1}^{T} \\log p_\\theta(y_t \\mid y_{<t})$$\n",
        "\n",
        "Where:\n",
        "- $y_t$ is the target token at timestep $t$\n",
        "- The model learns to predict the next token given all previous tokens\n",
        "- Padding tokens are masked out during loss computation\n",
        "\n",
        "\n",
        "## Why Use `SFTTrainer`?\n",
        "\n",
        "1. **Simplicity** : `SFTTrainer` is the simplest and most commonly used method to adapt a language model to a target dataset. It requires minimal configuration to get started.\n",
        "2. **Flexible Data Format Support** :\n",
        "`SFTTrainer` supports multiple dataset formats out of the box:\n",
        "\n",
        "```python\n",
        "        # Standard language modeling\n",
        "        {\"text\": \"The sky is blue.\"} - For the sake of simplicity, we are using this chat template.\n",
        "\n",
        "        # Conversational language modeling\n",
        "        {\"messages\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
        "                    {\"role\": \"assistant\", \"content\": \"It is blue.\"}]}\n",
        "\n",
        "        # Standard prompt-completion\n",
        "        {\"prompt\": \"The sky is\",\n",
        "        \"completion\": \" blue.\"}\n",
        "\n",
        "        # Conversational prompt-completion\n",
        "        {\"prompt\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}],\n",
        "        \"completion\": [{\"role\": \"assistant\", \"content\": \"It is blue.\"}]}\n",
        "```\n",
        "3. **PEFT Integration**\n",
        "Seamless integration with the PEFT (Parameter-Efficient Fine-Tuning) library, enabling:\n",
        "- **LoRA** (Low-Rank Adaptation)\n",
        "- **QLoRA** (Quantized LoRA with 4-bit quantization)\n",
        "- Other adapter-based methods\n",
        "4. **Memory Efficiency Features**\n",
        "- **Packing**: Group multiple sequences into fixed-length blocks\n",
        "- **Gradient checkpointing**: Reduce memory usage during training\n",
        "- **Padding-free training**: Eliminate padding overhead with FlashAttention\n",
        "\n",
        "5. **Automatic Chat Template Handling**\n",
        "When provided with conversational datasets, the trainer automatically applies the appropriate chat template.\n",
        "\n",
        "\n",
        "### When Should You Use `SFTTrainer`?\n",
        "\n",
        "Use `SFTTrainer` when you want to:\n",
        "\n",
        "- perform **supervised fine-tuning** on a dataset that provides clear input-output pairs or prompt-completion pairs,\n",
        "- adapt an LLM to a task where you expect the model to produce specific output sequences given input sequences,\n",
        "- develop instruction-tuned models intended to follow human instructions (for example medical QA tasks),\n",
        "- train models using various dataset formats without manually implementing tokenization and loss computation. :contentReference[oaicite:3]{index=3}\n",
        "\n",
        "\n",
        "\n",
        "## SFTConfig: Configuration Parameters\n",
        "\n",
        "`SFTConfig` is the configuration class for `SFTTrainer`. It inherits from `TrainingArguments` and adds SFT-specific parameters.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "```python\n",
        "        from trl import SFTConfig\n",
        "\n",
        "        config = SFTConfig(\n",
        "            # Output and Logging\n",
        "            output_dir=\"./results\",                    # Directory for saving checkpoints\n",
        "            logging_steps=10,                          # Log metrics every N steps\n",
        "            \n",
        "            # Training Hyperparameters\n",
        "            num_train_epochs=3,                        # Number of training epochs\n",
        "            per_device_train_batch_size=4,             # Batch size per GPU\n",
        "            gradient_accumulation_steps=4,             # Accumulate gradients over N steps\n",
        "            learning_rate=2e-4,                        # Learning rate (higher for adapters ~1e-4)\n",
        "            \n",
        "            # Optimization\n",
        "            optim=\"adamw_torch_fused\",                 # Optimizer choice\n",
        "            lr_scheduler_type=\"cosine\",                # Learning rate scheduler\n",
        "            warmup_ratio=0.1,                          # Warmup steps ratio\n",
        "            weight_decay=0.01,                         # L2 regularization\n",
        "            max_grad_norm=1.0,                         # Gradient clipping\n",
        "            \n",
        "            # Memory Optimization\n",
        "            gradient_checkpointing=True,               # Enable gradient checkpointing\n",
        "            bf16=True,                                 # Use bfloat16 precision\n",
        "            \n",
        "            # Data Processing\n",
        "            max_length=1024,                           # Maximum sequence length\n",
        "            packing=False,                             # Enable sequence packing\n",
        "            dataset_num_proc=4,                        # Number of preprocessing workers\n",
        "            \n",
        "            # Loss Configuration\n",
        "            completion_only_loss=True,                 # Compute loss only on completions\n",
        "            assistant_only_loss=False,                 # Compute loss only on assistant messages\n",
        "            \n",
        "            # Saving\n",
        "            save_strategy=\"steps\",                     # When to save checkpoints\n",
        "            save_steps=500,                            # Save every N steps\n",
        "            save_total_limit=3,                        # Keep only last N checkpoints\n",
        "        )\n",
        "```\n",
        "\n",
        "### Important SFT-Specific Parameters\n",
        "\n",
        "| Parameter | Type | Default | Description |\n",
        "|-----------|------|---------|-------------|\n",
        "| `max_length` | `int` | 1024 | Maximum sequence length. Sequences are truncated from the right |\n",
        "| `packing` | `bool` | False | Pack multiple sequences into fixed-length blocks for efficiency |\n",
        "| `completion_only_loss` | `bool` | None | Compute loss only on completion tokens (not prompt) |\n",
        "| `assistant_only_loss` | `bool` | False | Compute loss only on assistant messages in conversations |\n",
        "| `dataset_text_field` | `str` | \"text\" | Column name containing text data |\n",
        "| `model_init_kwargs` | `dict` | None | Kwargs passed to `from_pretrained()` |\n",
        "| `chat_template_path` | `str` | None | Path to custom chat template |\n",
        "\n",
        "\n",
        "## `SFTTrainer`: The Main Trainer Class\n",
        "\n",
        "### Basic Usage\n",
        "\n",
        "```python\n",
        "        from trl import SFTTrainer, SFTConfig\n",
        "        from datasets import load_dataset\n",
        "\n",
        "        # Minimal example\n",
        "        trainer = SFTTrainer(\n",
        "            model=\"Qwen/Qwen3-0.6B\",\n",
        "            train_dataset=load_dataset(\"trl-lib/Capybara\", split=\"train\"),\n",
        "        )\n",
        "        trainer.train()\n",
        "```\n",
        "\n",
        "### Constructor Parameters\n",
        "\n",
        "```python\n",
        "        from trl import SFTTrainer\n",
        "\n",
        "        trainer = SFTTrainer(\n",
        "            model=\"model_name_or_path\",     # Model ID or PreTrainedModel\n",
        "            args=SFTConfig(...),            # Training configuration\n",
        "            train_dataset=dataset,          # Training dataset\n",
        "            eval_dataset=eval_dataset,      # Optional: evaluation dataset\n",
        "            processing_class=tokenizer,     # Optional: tokenizer/processor\n",
        "            peft_config=LoraConfig(...),    # Optional: PEFT configuration\n",
        "            formatting_func=format_fn,      # Optional: custom formatting function\n",
        "            data_collator=collator,         # Optional: custom data collator\n",
        "            callbacks=[...],                # Optional: training callbacks\n",
        "        )\n",
        "```\n",
        "\n",
        "### Key Methods\n",
        "\n",
        "| Method | Description |\n",
        "|--------|-------------|\n",
        "| `trainer.train()` | Start the training loop |\n",
        "| `trainer.evaluate()` | Run evaluation on eval dataset |\n",
        "| `trainer.save_model()` | Save the model to disk |\n",
        "| `trainer.push_to_hub()` | Upload model to Hugging Face Hub |\n",
        "\n",
        "\n",
        "### Using `SFTTrainer` with QLoRA (4-bit Quantization)\n",
        "\n",
        "For memory-efficient fine-tuning on medical MCQA datasets, combining `SFTTrainer` with QLoRA is highly recommended:\n",
        "\n",
        "```python\n",
        "        from transformers import BitsAndBytesConfig\n",
        "        from peft import LoraConfig\n",
        "        from trl import SFTTrainer, SFTConfig\n",
        "        from datasets import load_dataset\n",
        "        import torch\n",
        "\n",
        "        # 4-bit Quantization Configuration (NF4)\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",              # NormalFloat4 quantization\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,  # Computation dtype\n",
        "            bnb_4bit_use_double_quant=True,         # Nested quantization\n",
        "        )\n",
        "\n",
        "        # LoRA Configuration\n",
        "        lora_config = LoraConfig(\n",
        "            r=16,                          # Rank of update matrices\n",
        "            lora_alpha=32,                 # Scaling factor\n",
        "            lora_dropout=0.05,             # Dropout probability\n",
        "            target_modules=[               # Modules to apply LoRA\n",
        "                \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "            ],\n",
        "            bias=\"none\",                   # Bias handling\n",
        "            task_type=\"CAUSAL_LM\",         # Task type\n",
        "        )\n",
        "\n",
        "        # SFT Configuration\n",
        "        sft_config = SFTConfig(\n",
        "            output_dir=\"./medical-mcqa-qlora\",\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=4,\n",
        "            gradient_accumulation_steps=4,\n",
        "            learning_rate=2e-4,            # Higher LR for adapter training\n",
        "            max_length=512,\n",
        "            gradient_checkpointing=True,\n",
        "            bf16=True,\n",
        "            logging_steps=10,\n",
        "            save_strategy=\"epoch\",\n",
        "            optim=\"paged_adamw_8bit\",      # Memory-efficient optimizer\n",
        "        )\n",
        "\n",
        "        # Initialize Trainer with QLoRA\n",
        "        trainer = SFTTrainer(\n",
        "            model=\"meta-llama/Llama-3.1-8B\",\n",
        "            args=sft_config,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            peft_config=lora_config,\n",
        "            model_init_kwargs={\n",
        "                \"quantization_config\": bnb_config,\n",
        "                \"device_map\": \"auto\",\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # Start Training\n",
        "        trainer.train()\n",
        "```\n",
        "\n",
        "\n",
        "### Preparing Medical MCQA Data for SFTTrainer\n",
        "\n",
        "For medical MCQA datasets, you'll typically need to preprocess your data into the format which we earlier discussed.\n",
        "\n",
        "\n",
        "\n",
        "### Logged Metrics During Training\n",
        "\n",
        "`SFTTrainer` automatically logs the following metrics:\n",
        "\n",
        "| Metric | Description |\n",
        "|--------|-------------|\n",
        "| `loss` | Average cross-entropy loss on non-masked tokens |\n",
        "| `entropy` | Average entropy of predicted token distribution |\n",
        "| `mean_token_accuracy` | Proportion of correct top-1 predictions |\n",
        "| `learning_rate` | Current learning rate |\n",
        "| `grad_norm` | L2 norm of gradients (before clipping) |\n",
        "| `epoch` | Current epoch number |\n",
        "| `global_step` | Total optimizer steps taken |\n",
        "| `num_tokens` | Total tokens processed |\n",
        "\n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        "- [TRL Documentation - SFT Trainer](https://huggingface.co/docs/trl/en/sft_trainer)\n",
        "- [PEFT Library](https://huggingface.co/docs/peft)\n",
        "- [BitsAndBytes Quantization](https://huggingface.co/docs/bitsandbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaXa9LETUsCE"
      },
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "training_args = SFTConfig(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "\n",
        "    # Training hyperparameters\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    max_steps=MAX_STEPS,             # Override epochs for quick demo Please comment it if you are training it for longer duration\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
        "\n",
        "    # Optimizer settings\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.03,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "\n",
        "    # Memory optimization\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"paged_adamw_8bit\",       # Memory-efficient optimizer\n",
        "    bf16=True,                       # Use bfloat16\n",
        "\n",
        "    # Logging\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    logging_first_step=True,\n",
        "\n",
        "    # Evaluation\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "\n",
        "    # Saving\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    # SFT specific\n",
        "    max_length=MAX_SEQ_LENGTH,\n",
        "    dataset_text_field=\"text\",\n",
        "    packing=False,                   # Don't pack multiple examples\n",
        "\n",
        "    # Misc\n",
        "    report_to=\"none\",                # Disable W&B for tutorial\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "print(\"Training arguments configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exsljmFKgrdb"
      },
      "source": [
        "## Optimizers for LLM Fine-Tuning\n",
        "\n",
        "\n",
        "**Adam (Adaptive Moment Estimation)** is the most widely used optimizer for training neural networks. It combines two key ideas:\n",
        "\n",
        "- **Momentum**: Tracks exponentially weighted average of past gradients (first moment)\n",
        "- **RMSprop**: Tracks exponentially weighted average of squared gradients (second moment)\n",
        "\n",
        "**Problem**:\n",
        "- Adam stores two state tensors (momentum + variance) per parameter, requiring **8 bytes per parameter** in 32-bit precision.\n",
        "- For a 7B model, this means ~56GB just for optimizer states.\n",
        "\n",
        "### Why Memory-Efficient Optimizers Matter\n",
        "\n",
        "| Component | Memory per Parameter |\n",
        "|-----------|---------------------|\n",
        "| Model weights (fp16) | 2 bytes |\n",
        "| Gradients (fp16) | 2 bytes |\n",
        "| Adam states (fp32) | 8 bytes |\n",
        "| **Total** | **12 bytes** |\n",
        "\n",
        "For a 7B parameter model: 7B x 12 bytes = **84GB minimum** just for training.\n",
        "\n",
        "### 8-bit Optimizers (BitsAndBytes)\n",
        "\n",
        "8-bit optimizers reduce optimizer state memory from 8 bytes to 2 bytes per parameter (75% reduction) with no accuracy loss.\n",
        "\n",
        "### How They Work\n",
        "\n",
        "1. **Block-wise Quantization**: Divides tensors into blocks, quantizes each independently to isolate outliers\n",
        "2. **Dynamic Quantization**: Adapts quantization range per block based on value distribution\n",
        "3. **Dequantize-Compute-Quantize**: States stored in 8-bit, computation done in 32-bit precision\n",
        "\n",
        "### Available 8-bit Optimizers\n",
        "\n",
        "| Optimizer | Description |\n",
        "|-----------|-------------|\n",
        "| `adamw_bnb_8bit` | 8-bit AdamW from bitsandbytes |\n",
        "| `adamw_8bit` | Alias for adamw_bnb_8bit |\n",
        "| `lion_8bit` | 8-bit Lion optimizer |\n",
        "| `ademamix_8bit` | 8-bit AdEMAMix optimizer |\n",
        "\n",
        "### Paged Optimizers\n",
        "\n",
        "Paged optimizers add **CPU memory offloading** on top of quantization using CUDA Unified Memory.\n",
        "\n",
        "### How Paging Works\n",
        "\n",
        "- Memory pages are pre-allocated on CPU\n",
        "- When GPU memory is exhausted, optimizer states automatically transfer to CPU\n",
        "- Pages transfer back to GPU only when needed for computation\n",
        "- Acts as a safety net against out-of-memory errors\n",
        "\n",
        "### Available Paged Optimizers\n",
        "\n",
        "| Optimizer | Description |\n",
        "|-----------|-------------|\n",
        "| `paged_adamw_32bit` | 32-bit AdamW with CPU paging |\n",
        "| `paged_adamw_8bit` | 8-bit AdamW with CPU paging |\n",
        "| `paged_lion_32bit` | 32-bit Lion with CPU paging |\n",
        "| `paged_lion_8bit` | 8-bit Lion with CPU paging |\n",
        "\n",
        "\n",
        "### paged_adamw_8bit (Important)\n",
        "\n",
        "This optimizer combines **8-bit quantization** and **CPU paging** for maximum memory efficiency.\n",
        "\n",
        "### When to Use\n",
        "\n",
        "| Scenario | Recommendation |\n",
        "|----------|---------------|\n",
        "| QLoRA fine-tuning | Best choice |\n",
        "| GPU memory below 16GB | Recommended |\n",
        "| Frequent OOM errors | Recommended |\n",
        "| Abundant GPU memory | Use adamw_bnb_8bit instead (faster) |\n",
        "\n",
        "### Trade-offs\n",
        "\n",
        "| Aspect | paged_adamw_8bit |\n",
        "|--------|------------------|\n",
        "| Memory | Lowest (8-bit + CPU offload) |\n",
        "| Speed | Slower when paging occurs |\n",
        "| Stability | High (prevents OOM crashes) |\n",
        "| Accuracy | Same as 32-bit Adam |\n",
        "\n",
        "### Performance Notes\n",
        "\n",
        "- Paging only activates when GPU memory is full\n",
        "- Transfer speed is approximately 50% of full PCIe bandwidth\n",
        "- Best combined with gradient checkpointing\n",
        "- Minimal overhead when GPU memory is sufficient\n",
        "\n",
        "\n",
        "### Comparison: adamw_bnb_8bit vs paged_adamw_8bit\n",
        "\n",
        "| Feature | adamw_bnb_8bit | paged_adamw_8bit |\n",
        "|---------|----------------|------------------|\n",
        "| Optimizer state memory | 75% reduction | 75% reduction + CPU offload |\n",
        "| Training speed | Faster | Slower when paging active |\n",
        "| OOM protection | No | Yes |\n",
        "| Best use case | Sufficient GPU memory | Limited GPU memory, QLoRA |\n",
        "\n",
        "**Decision**: If unsure about memory, use `paged_adamw_8bit`. If memory is sufficient, use `adamw_bnb_8bit` for speed.\n",
        "\n",
        "\n",
        "### Other Memory-Efficient Options\n",
        "- Adafactor\n",
        "- Lion\n",
        "- GaLore\n",
        "\n",
        "### All Supported Optimizers in HuggingFace\n",
        "\n",
        "1. Standard : `adamw_torch`, `adamw_torch_fused`, `adafactor`, `sgd`, `adagrad`, `rmsprop`\n",
        "2. BitsAndBytes 8-bit : `adamw_bnb_8bit`, `adamw_8bit`, `lion_8bit`, `ademamix_8bit`\n",
        "3. BitsAndBytes Paged : `paged_adamw_32bit`, `paged_adamw_8bit`, `paged_lion_32bit`, `paged_lion_8bit`, `paged_ademamix_32bit`, `paged_ademamix_8bit`\n",
        "4. Specialized : `galore_adamw`, `galore_adamw_8bit`, `lomo`, `adalomo`, `schedule_free_adamw`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI7p4p5Ygrdb"
      },
      "source": [
        "### Initializing the Trainer\n",
        "\n",
        "**SFTTrainer** (Supervised Fine-Tuning Trainer) handles the training loop:\n",
        "- Manages batching and gradient updates\n",
        "- Handles evaluation on validation set\n",
        "- Saves checkpoints\n",
        "- Logs metrics\n",
        "\n",
        "Everything is now ready for training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUs-LcVHUtgy"
      },
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['validation'],\n",
        "    processing_class=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized!\")\n",
        "print(f\"\\nTraining setup:\")\n",
        "print(f\"  Training examples: {len(dataset['train'])}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION}\")\n",
        "print(f\"  Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION}\")\n",
        "print(f\"  Max steps: {MAX_STEPS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TfWWOSxgrdb"
      },
      "source": [
        "## Part 11: Training the Model\n",
        "\n",
        "### Starting Training\n",
        "\n",
        "This will:\n",
        "- Run 200 training steps (adjust MAX_STEPS for longer training)\n",
        "- Evaluate on validation set every 50 steps\n",
        "- Save checkpoints every 50 steps\n",
        "- Display progress bars and loss metrics\n",
        "\n",
        "**Expected time**: 10-30 minutes depending on your GPU\n",
        "\n",
        "Watch the loss decrease - this indicates the model is learning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0RJYHbmUwcN"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "train_result = trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGstco1egrdb"
      },
      "source": [
        "### Training Results Summary\n",
        "\n",
        "After training completes, we examine:\n",
        "- **Training loss**: Lower is better (indicates model fit to training data)\n",
        "- **Training time**: Total time spent\n",
        "- **Throughput**: How many examples processed per second"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOzL6PSrU2Hz"
      },
      "outputs": [],
      "source": [
        "# Print training metrics\n",
        "print(\"\\nTraining Metrics:\")\n",
        "print(f\"Total steps: {train_result.global_step}\")\n",
        "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"Training time: {train_result.metrics['train_runtime']:.1f} seconds\")\n",
        "print(f\"Samples/second: {train_result.metrics['train_samples_per_second']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzOyrhksgrdb"
      },
      "source": [
        "## Part 12: Quick Validation Check\n",
        "\n",
        "### Evaluating Accuracy on Validation Set\n",
        "\n",
        "This performs a quick accuracy check:\n",
        "1. Generate answers for validation examples\n",
        "2. Extract predicted answer (A, B, C, or D)\n",
        "3. Compare to correct answer\n",
        "4. Calculate accuracy percentage\n",
        "\n",
        "**Random baseline**: 25% (since there are 4 choices)\n",
        "If our model is performing above 25%, it's learning something useful!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njr_cMOT3Wo1"
      },
      "outputs": [],
      "source": [
        "# Quick Accuracy Check on Validation Set\n",
        "# Set model to eval mode\n",
        "model.eval()\n",
        "\n",
        "def extract_mcq_answer(text):\n",
        "    \"\"\"Extract answer letter (A, B, C, or D) from model output.\"\"\"\n",
        "    import re\n",
        "    patterns = [\n",
        "        r'correct answer is\\s*([A-Da-d])',\n",
        "        r'answer is\\s*([A-Da-d])',\n",
        "        r'^\\s*([A-Da-d])\\)',\n",
        "        r'\\b([A-Da-d])\\)',\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group(1).upper()\n",
        "    # Fallback: look for first A/B/C/D in response\n",
        "    for char in text[:50]:\n",
        "        if char.upper() in ['A', 'B', 'C', 'D']:\n",
        "            return char.upper()\n",
        "    return None\n",
        "\n",
        "# Evaluate on a sample of validation data\n",
        "num_samples = min(50, len(dataset['validation']))\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "print(f\"\\nEvaluating on {num_samples} validation samples...\")\n",
        "\n",
        "for i in range(num_samples):\n",
        "    example = dataset['validation'][i]\n",
        "\n",
        "    # Generate response\n",
        "    inputs = tokenizer(example['text'].split(\"### Response:\")[0] + \"### Response:\\n\",\n",
        "                      return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=150,\n",
        "            temperature=0.1,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    # Extract predicted and correct answers\n",
        "    predicted = extract_mcq_answer(response)\n",
        "    correct_answer = extract_mcq_answer(example['text'].split(\"### Response:\")[1])\n",
        "\n",
        "    if predicted == correct_answer:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "    # Progress indicator\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  Processed {i + 1}/{num_samples}...\")\n",
        "\n",
        "accuracy = (correct / total * 100) if total > 0 else 0\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.1f}% ({correct}/{total} correct)\")\n",
        "print(f\"Random baseline: 25% (4 choices)\")\n",
        "\n",
        "\n",
        "if accuracy > 25:\n",
        "    print(f\"Model is {accuracy - 25:.1f}% better than random!\")\n",
        "else:\n",
        "    print(\"Model performing at or below random baseline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PZ2Idchgrdb"
      },
      "source": [
        "### Saving the Fine-Tuned Adapter\n",
        "\n",
        "We save:\n",
        "- **Adapter weights**: The trained LoRA parameters (~10-50MB)\n",
        "- **Tokenizer**: To ensure consistent text processing\n",
        "- **Configuration**: LoRA settings for later loading\n",
        "\n",
        "These files are much smaller than a full model, making them easy to share and version control."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR-mfWxCU3PT"
      },
      "outputs": [],
      "source": [
        "# Save the LoRA adapter\n",
        "ADAPTER_PATH = f\"{OUTPUT_DIR}/final_adapter\"\n",
        "\n",
        "print(f\"Saving adapter to {ADAPTER_PATH}...\")\n",
        "model.save_pretrained(ADAPTER_PATH)\n",
        "tokenizer.save_pretrained(ADAPTER_PATH)\n",
        "\n",
        "print(\"\\nModel saved!\")\n",
        "print(f\"\\nSaved files:\")\n",
        "!ls -la {ADAPTER_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvjnTd_BU4X3"
      },
      "outputs": [],
      "source": [
        "# View adapter config\n",
        "print(\"\\nAdapter Configuration:\")\n",
        "!cat {ADAPTER_PATH}/adapter_config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtm7ncJRgrdc"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 12B: Training on PubMedQA Dataset\n",
        "\n",
        "Now we train a separate model on PubMedQA. PubMedQA is a yes/no/maybe question answering task based on biomedical research abstracts. This demonstrates fine-tuning for a different answer format compared to MedMCQA's multiple-choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjeTO9s6grdc"
      },
      "source": [
        "### PubMedQA Training Configuration\n",
        "\n",
        "We use similar hyperparameters as MedMCQA training, but adjust the output directory and max steps based on the smaller dataset size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90GnU0mRgrdc"
      },
      "outputs": [],
      "source": [
        "# PubMedQA Training Configuration\n",
        "PUBMEDQA_OUTPUT_DIR = \"./pubmedqa_llm_finetuned\"\n",
        "PUBMEDQA_MAX_STEPS = 10  # Fewer steps due to smaller dataset\n",
        "\n",
        "print(\"PubMedQA Training Configuration:\")\n",
        "print(f\"  Output directory: {PUBMEDQA_OUTPUT_DIR}\")\n",
        "print(f\"  Max steps: {PUBMEDQA_MAX_STEPS}\")\n",
        "print(f\"  Training examples: {len(pubmedqa_dataset['train'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4-4h2yKgrdc"
      },
      "source": [
        "### Reloading Base Model for PubMedQA\n",
        "\n",
        "We need to reload a fresh base model since the previous one has the MedMCQA adapter attached. This ensures clean training on PubMedQA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0uYA4Fcgrdc"
      },
      "outputs": [],
      "source": [
        "# Clear previous model from memory and reload for PubMedQA training\n",
        "import gc\n",
        "\n",
        "# Free memory from previous training\n",
        "# del model\n",
        "# del trainer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Loading fresh base model for PubMedQA training...\")\n",
        "\n",
        "pubmed_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "pubmed_model.gradient_checkpointing_enable()\n",
        "print(f\"Model loaded: {MODEL_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3AVYMMYgrdc"
      },
      "source": [
        "### Applying LoRA to PubMedQA Model\n",
        "\n",
        "We apply the same LoRA configuration to the new base model. The adapter architecture remains identical, but the weights will be trained on PubMedQA data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SaKEHLpgrdc"
      },
      "source": [
        "## Task: Add LoRA to the PubMedQA Model\n",
        "\n",
        "**Goal:** Attach LoRA adapters to the PubMedQA base model so that only a small number of parameters are trained.\n",
        "\n",
        "### Steps to complete\n",
        "1. Create a LoRA configuration  \n",
        "   - Choose a low-rank value, a scaling value, and a dropout value  \n",
        "   - Do not update any bias terms  \n",
        "   - Set the task type for a causal language model  \n",
        "   - Select the attention and feed-forward projection layers where LoRA will be applied  \n",
        "\n",
        "2. Display the LoRA setup  \n",
        "   - Print the chosen rank  \n",
        "   - Print the scaling value  \n",
        "   - Show how the scaling depends on the rank  \n",
        "   - Print the list of layers where LoRA is applied  \n",
        "\n",
        "3. Prepare the model for low-bit training  \n",
        "   - Enable memory-saving features so training fits on the GPU  \n",
        "\n",
        "4. Apply LoRA adapters to the model  \n",
        "   - Attach the LoRA configuration to the PubMedQA model  \n",
        "\n",
        "5. Check the result  \n",
        "   - Print a message confirming LoRA is applied  \n",
        "   - Display how many parameters are trainable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K3lMuVVgrdc"
      },
      "source": [
        "# REMOVE THIS CODE BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D7eSX5egrdc"
      },
      "outputs": [],
      "source": [
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=LORA_R,                    # Rank of the update matrices\n",
        "    lora_alpha=LORA_ALPHA,       # Scaling factor\n",
        "    lora_dropout=LORA_DROPOUT,   # Dropout probability\n",
        "    bias=\"none\",                 # Don't train biases\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    target_modules=[             # Which layers to apply LoRA to\n",
        "        \"q_proj\",   # Query projection\n",
        "        \"k_proj\",   # Key projection\n",
        "        \"v_proj\",   # Value projection\n",
        "        \"o_proj\",   # Output projection\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"LoRA configuration ready!\")\n",
        "print(f\"\\nLoRA Settings:\")\n",
        "print(f\"Rank (r): {LORA_R}\")\n",
        "print(f\"Alpha: {LORA_ALPHA}\")\n",
        "print(f\"Effective scaling: {LORA_ALPHA/LORA_R}\")\n",
        "print(f\"Target modules: {lora_config.target_modules}\")\n",
        "# Prepare model and apply LoRA\n",
        "pubmed_model = prepare_model_for_kbit_training(pubmed_model, use_gradient_checkpointing=True)\n",
        "\n",
        "# Use the same LoRA config as MedMCQA\n",
        "pubmed_model = get_peft_model(pubmed_model, lora_config)\n",
        "\n",
        "print(\"LoRA applied to PubMedQA model!\")\n",
        "print_trainable_parameters(pubmed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o23OTNjgrdd"
      },
      "source": [
        "### Setting Up PubMedQA Training Arguments\n",
        "\n",
        "Training configuration for PubMedQA follows the same pattern as MedMCQA but with adjusted output directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkD0ZJcLgrdd"
      },
      "source": [
        "## Task: Configure Training and Run SFT on PubMedQA\n",
        "\n",
        "**Goal:** Set up training settings and train the PubMedQA model using the SFT trainer.\n",
        "\n",
        "### Steps to complete\n",
        "1. Create training settings  \n",
        "   - Choose a folder where training outputs will be saved  \n",
        "   - Set how long the model should train  \n",
        "   - Decide batch size and how often gradients are accumulated  \n",
        "   - Select a learning rate strategy and basic optimizer behavior  \n",
        "\n",
        "2. Enable memory friendly training  \n",
        "   - Turn on features that reduce GPU memory usage  \n",
        "   - Use a low memory optimizer and mixed precision  \n",
        "\n",
        "3. Add logging and evaluation  \n",
        "   - Decide how often training progress is printed  \n",
        "   - Set regular evaluation during training  \n",
        "   - Save model checkpoints at fixed intervals  \n",
        "\n",
        "4. Add SFT specific settings  \n",
        "   - Define the maximum input length  \n",
        "   - Specify which dataset field contains the text  \n",
        "   - Decide whether examples are packed or kept separate  \n",
        "\n",
        "5. Initialize the trainer  \n",
        "   - Create an SFT trainer using the model, training settings, and tokenizer  \n",
        "   - Provide the training and validation datasets  \n",
        "\n",
        "6. Verify the setup  \n",
        "   - Print a short summary showing dataset sizes and training length  \n",
        "\n",
        "7. Start training  \n",
        "   - Run the training loop and store the final training result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D9R-HQEgrdd"
      },
      "source": [
        "REMOVE THE CODE BLOCK BELOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUcsI-0agrdd"
      },
      "outputs": [],
      "source": [
        "# PubMedQA Training Arguments\n",
        "pubmedqa_training_args = SFTConfig(\n",
        "    output_dir=PUBMEDQA_OUTPUT_DIR,\n",
        "\n",
        "    # Training hyperparameters\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    max_steps=PUBMEDQA_MAX_STEPS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
        "\n",
        "    # Optimizer settings\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.03,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "\n",
        "    # Memory optimization\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    bf16=True,\n",
        "\n",
        "    # Logging\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    logging_first_step=True,\n",
        "\n",
        "    # Evaluation\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "\n",
        "    # Saving\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    # SFT specific\n",
        "    max_length=MAX_SEQ_LENGTH,\n",
        "    dataset_text_field=\"text\",\n",
        "    packing=False,\n",
        "\n",
        "    # Misc\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "print(\"PubMedQA training arguments configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwVIMdb-grdd"
      },
      "source": [
        "### Initializing PubMedQA Trainer\n",
        "\n",
        "We create a new SFTTrainer instance for PubMedQA with the PubMedQA-specific dataset and training arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V-chnZsgrdd"
      },
      "outputs": [],
      "source": [
        "# Create PubMedQA trainer\n",
        "pubmed_trainer = SFTTrainer(\n",
        "    model=pubmed_model,\n",
        "    args=pubmedqa_training_args,\n",
        "    train_dataset=pubmedqa_dataset['train'],\n",
        "    eval_dataset=pubmedqa_dataset['validation'],\n",
        "    processing_class=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"PubMedQA Trainer initialized!\")\n",
        "print(f\"\\nTraining setup:\")\n",
        "print(f\"  Training examples: {len(pubmedqa_dataset['train'])}\")\n",
        "print(f\"  Validation examples: {len(pubmedqa_dataset['validation'])}\")\n",
        "print(f\"  Max steps: {PUBMEDQA_MAX_STEPS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnyhFaeKgrdd"
      },
      "source": [
        "### Training on PubMedQA\n",
        "\n",
        "Now we run the training loop for PubMedQA. The model learns to answer yes/no/maybe questions based on biomedical research context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNwgLLXOgrdd"
      },
      "outputs": [],
      "source": [
        "# Train on PubMedQA\n",
        "print(\"Starting PubMedQA training...\")\n",
        "pubmed_train_result = pubmed_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfkH4Qlxgrdd"
      },
      "source": [
        "### PubMedQA Training Results\n",
        "\n",
        "We examine the training metrics for PubMedQA to verify the model has learned from the biomedical QA data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLCpOYQggrdd"
      },
      "outputs": [],
      "source": [
        "# Print PubMedQA training metrics\n",
        "print(\"\\nPubMedQA Training Metrics:\")\n",
        "print(f\"Total steps: {pubmed_train_result.global_step}\")\n",
        "print(f\"Training loss: {pubmed_train_result.training_loss:.4f}\")\n",
        "print(f\"Training time: {pubmed_train_result.metrics['train_runtime']:.1f} seconds\")\n",
        "print(f\"Samples/second: {pubmed_train_result.metrics['train_samples_per_second']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L8xAnMAgrde"
      },
      "source": [
        "### PubMedQA Validation Check\n",
        "\n",
        "We evaluate the fine-tuned model on the PubMedQA validation set. Since PubMedQA has yes/no/maybe answers, we use a different answer extraction approach than MedMCQA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl7ZlJHGgrde"
      },
      "outputs": [],
      "source": [
        "# PubMedQA Validation Accuracy Check\n",
        "pubmed_model.eval()\n",
        "\n",
        "def extract_pubmedqa_answer(text):\n",
        "    \"\"\"Extract yes/no/maybe answer from model output.\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    # Check for explicit answers at the beginning\n",
        "    if text_lower.startswith('yes'):\n",
        "        return 'yes'\n",
        "    elif text_lower.startswith('no'):\n",
        "        return 'no'\n",
        "    elif text_lower.startswith('maybe'):\n",
        "        return 'maybe'\n",
        "    # Check within the first part of response\n",
        "    first_part = text_lower[:100]\n",
        "    if 'yes.' in first_part or 'yes,' in first_part or 'yes ' in first_part:\n",
        "        return 'yes'\n",
        "    elif 'no.' in first_part or 'no,' in first_part or 'no ' in first_part:\n",
        "        return 'no'\n",
        "    elif 'maybe' in first_part:\n",
        "        return 'maybe'\n",
        "    return None\n",
        "\n",
        "# Evaluate on validation samples\n",
        "num_samples = min(30, len(pubmedqa_dataset['validation']))\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "print(f\"\\nEvaluating PubMedQA on {num_samples} validation samples...\")\n",
        "\n",
        "for i in range(num_samples):\n",
        "    example = pubmedqa_dataset['validation'][i]\n",
        "\n",
        "    # Generate response\n",
        "    prompt_text = example['text'].split(\"### Response:\")[0] + \"### Response:\\n\"\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\", truncation=True, max_length=1024).to(pubmed_model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = pubmed_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=150,\n",
        "            temperature=0.1,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    # Extract predicted and correct answers\n",
        "    predicted = extract_pubmedqa_answer(response)\n",
        "    correct_text = example['text'].split(\"### Response:\")[1].strip()\n",
        "    correct_answer = extract_pubmedqa_answer(correct_text)\n",
        "\n",
        "    if predicted == correct_answer:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  Processed {i + 1}/{num_samples}...\")\n",
        "\n",
        "accuracy = (correct / total * 100) if total > 0 else 0\n",
        "\n",
        "print(f\"\\nPubMedQA Accuracy: {accuracy:.1f}% ({correct}/{total} correct)\")\n",
        "print(f\"Random baseline: 33.3% (3 choices: yes/no/maybe)\")\n",
        "\n",
        "if accuracy > 33.3:\n",
        "    print(f\"Model is {accuracy - 33.3:.1f}% better than random!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15NSb8X8grde"
      },
      "source": [
        "### Saving PubMedQA Fine-Tuned Adapter\n",
        "\n",
        "We save the trained PubMedQA adapter separately from the MedMCQA adapter. This allows using either model for its respective task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5v7kjW2grde"
      },
      "outputs": [],
      "source": [
        "# Save the PubMedQA LoRA adapter\n",
        "PUBMEDQA_ADAPTER_PATH = f\"{PUBMEDQA_OUTPUT_DIR}/final_adapter\"\n",
        "\n",
        "print(f\"Saving PubMedQA adapter to {PUBMEDQA_ADAPTER_PATH}...\")\n",
        "pubmed_model.save_pretrained(PUBMEDQA_ADAPTER_PATH)\n",
        "tokenizer.save_pretrained(PUBMEDQA_ADAPTER_PATH)\n",
        "\n",
        "print(\"\\nPubMedQA Model saved!\")\n",
        "print(f\"\\nSaved files:\")\n",
        "!ls -la {PUBMEDQA_ADAPTER_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qXKkOS7grde"
      },
      "source": [
        "### Testing PubMedQA Model\n",
        "\n",
        "We test the fine-tuned PubMedQA model on a sample biomedical question to see how it handles yes/no/maybe reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3lP2kdlgrde"
      },
      "outputs": [],
      "source": [
        "# Test PubMedQA model\n",
        "pubmedqa_test_prompt = \"\"\"### Instruction:\n",
        "You are a medical expert. Based on the provided research context, answer the following yes/no/maybe question. Provide a brief explanation for your answer.\n",
        "\n",
        "### Input:\n",
        "Context: A recent study investigated the efficacy of aspirin in preventing cardiovascular events in diabetic patients. The randomized controlled trial included 15,000 participants with type 2 diabetes but no prior cardiovascular disease. After a median follow-up of 7.4 years, patients receiving daily low-dose aspirin showed a 12% relative risk reduction in serious vascular events compared to placebo. However, the aspirin group also experienced a 29% increase in major bleeding events.\n",
        "\n",
        "Question: Should aspirin be routinely prescribed for primary prevention in diabetic patients?\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "print(\"Test Prompt for PubMedQA model:\")\n",
        "print(pubmedqa_test_prompt)\n",
        "\n",
        "# Generate response\n",
        "inputs = tokenizer(pubmedqa_test_prompt, return_tensors=\"pt\").to(pubmed_model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = pubmed_model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=200,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PUBMEDQA FINE-TUNED MODEL RESPONSE\")\n",
        "print(\"=\" * 80)\n",
        "print(response.split(\"### Response:\")[1] if \"### Response:\" in response else response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3GrLBosgrde"
      },
      "source": [
        "### Visualizing PubMedQA Training Progress\n",
        "\n",
        "We plot the training loss to verify the model learned from the PubMedQA dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gudj0l7Sgrde"
      },
      "outputs": [],
      "source": [
        "# Plot PubMedQA training progress\n",
        "pubmed_history = pubmed_trainer.state.log_history\n",
        "\n",
        "pubmed_train_losses = [(h['step'], h['loss']) for h in pubmed_history if 'loss' in h]\n",
        "pubmed_eval_losses = [(h['step'], h['eval_loss']) for h in pubmed_history if 'eval_loss' in h]\n",
        "\n",
        "if pubmed_train_losses:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    steps, losses = zip(*pubmed_train_losses)\n",
        "    plt.plot(steps, losses, label='Training Loss', color='purple', alpha=0.7)\n",
        "\n",
        "    if pubmed_eval_losses:\n",
        "        eval_steps, eval_loss_vals = zip(*pubmed_eval_losses)\n",
        "        plt.plot(eval_steps, eval_loss_vals, label='Validation Loss', color='orange', marker='o')\n",
        "\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('PubMedQA Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No training history available for plotting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP7pa54qgrde"
      },
      "source": [
        "## Part 13: Testing the Fine-Tuned Model\n",
        "\n",
        "### Creating a Test Prompt\n",
        "\n",
        "Let's test our model on a new medical question to see how it performs. We use the same Alpaca format the model was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTbdq6s-grde"
      },
      "source": [
        "## Generating Responses from Large Language Models\n",
        "\n",
        "### How Autoregressive Generation Works\n",
        "\n",
        "1. The model receives an input sequence (prompt)\n",
        "2. It outputs a probability distribution over all possible next tokens\n",
        "3. A token is selected from this distribution based on a decoding strategy\n",
        "4. The selected token is appended to the input sequence\n",
        "5. Steps 2-4 repeat until a stopping condition is met\n",
        "\n",
        "### Stopping Conditions\n",
        "\n",
        "- **End-of-Sequence (EOS) token**: Model generates a special token indicating completion\n",
        "- **Maximum length**: Predefined token limit is reached\n",
        "- **Stop strings**: Specific text patterns trigger stopping\n",
        "\n",
        "\n",
        "\n",
        "### Decoding Strategies\n",
        "\n",
        "| Strategy | Description | Use Case |\n",
        "|----------|-------------|----------|\n",
        "| **Greedy Search** | Picks highest probability token at each step | Fast, deterministic outputs |\n",
        "| **Beam Search** | Maintains multiple candidates, selects best overall | Higher quality, still deterministic |\n",
        "| **Sampling** | Randomly selects based on probability distribution | Creative, diverse outputs |\n",
        "\n",
        "\n",
        "\n",
        "## Common Generation Parameters\n",
        "\n",
        "### Length Control\n",
        "\n",
        "| Parameter | Default | Description |\n",
        "|-----------|---------|-------------|\n",
        "| `max_new_tokens` | None | Maximum tokens to generate (recommended) |\n",
        "| `max_length` | 20 | Total sequence length including prompt |\n",
        "| `min_new_tokens` | None | Minimum tokens to generate |\n",
        "\n",
        "### Sampling Parameters\n",
        "\n",
        "| Parameter | Default | Description |\n",
        "|-----------|---------|-------------|\n",
        "| `do_sample` | False | Enable probabilistic sampling |\n",
        "| `temperature` | 1.0 | Controls randomness (lower = focused, higher = random) |\n",
        "| `top_k` | 50 | Keep only top k probable tokens |\n",
        "| `top_p` | 1.0 | Keep tokens until cumulative probability reaches p |\n",
        "\n",
        "**Note**: temperature, top_k, and top_p only work when `do_sample=True`.\n",
        "\n",
        "### Temperature Effects\n",
        "\n",
        "| Value | Effect |\n",
        "|-------|--------|\n",
        "| < 1.0 | More deterministic, focused output |\n",
        "| = 1.0 | Original distribution |\n",
        "| > 1.0 | More random, creative output |\n",
        "| → 0 | Equivalent to greedy decoding |\n",
        " - Lower temperature (0.1-0.3) for more factual, consistent answers.\n",
        " - Higher temperature (0.7-1.0) for more creative, varied responses.\n",
        "\n",
        "### Repetition Control\n",
        "\n",
        "| Parameter | Default | Description |\n",
        "|-----------|---------|-------------|\n",
        "| `repetition_penalty` | 1.0 | Penalize repeated tokens (try 1.1-1.3) |\n",
        "| `no_repeat_ngram_size` | 0 | Prevent n-grams from repeating |\n",
        "\n",
        "### Beam Search Parameters\n",
        "\n",
        "| Parameter | Default | Description |\n",
        "|-----------|---------|-------------|\n",
        "| `num_beams` | 1 | Number of beams (1 = greedy) |\n",
        "| `early_stopping` | False | Stop when all beams complete |\n",
        "| `num_return_sequences` | 1 | Number of sequences to return |\n",
        "\n",
        "### Recommended Settings by Use Case\n",
        "\n",
        "These are general settings, you might need to change it accordingly based on your task.\n",
        "\n",
        "| Task | Key Parameters |\n",
        "|------|----------------|\n",
        "| **Factual QA** | `do_sample=False`, `max_new_tokens=256` |\n",
        "| **Creative Writing** | `do_sample=True`, `temperature=0.8`, `top_p=0.9` |\n",
        "| **Code Generation** | `temperature=0.2`, `max_new_tokens=512` |\n",
        "| **Summarization** | `num_beams=4`, `no_repeat_ngram_size=3` |\n",
        "\n",
        "### Common Pitfalls\n",
        "\n",
        "| Problem | Solution |\n",
        "|---------|----------|\n",
        "| Output too short | Set `max_new_tokens` explicitly |\n",
        "| Repetitive output | Use `repetition_penalty=1.2` or `no_repeat_ngram_size=2` |\n",
        "| Sampling not working | Ensure `do_sample=True` |\n",
        "| Incoherent output | Lower temperature (0.5-0.7) |\n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        "- **Text Generation API (Main Reference)**: [https://huggingface.co/docs/transformers/en/main_classes/text_generation](https://huggingface.co/docs/transformers/en/main_classes/text_generation)\n",
        "- **Generation Strategies Guide**: [https://huggingface.co/docs/transformers/en/generation_strategies](https://huggingface.co/docs/transformers/en/generation_strategies)\n",
        "- **LLM Tutorial**: [https://huggingface.co/docs/transformers/en/llm_tutorial](https://huggingface.co/docs/transformers/en/llm_tutorial)\n",
        "- **How to Generate Text (Blog)**: [https://huggingface.co/blog/how-to-generate](https://huggingface.co/blog/how-to-generate)\n",
        "- **Generation Utilities (Internal)**: [https://huggingface.co/docs/transformers/en/internal/generation_utils](https://huggingface.co/docs/transformers/en/internal/generation_utils)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt6jWhl1U5ls"
      },
      "outputs": [],
      "source": [
        "# Set model to evaluation mode\n",
        "pubmed_model.eval()\n",
        "\n",
        "# Test prompt\n",
        "test_prompt = \"\"\"### Instruction:\n",
        "You are a medical expert. Answer the following multiple-choice medical question. Choose the correct option and provide a brief explanation.\n",
        "\n",
        "### Input:\n",
        "Question: Which of the following is the most common cause of viral pneumonia in adults?\n",
        "\n",
        "Options:\n",
        "A) Respiratory syncytial virus\n",
        "B) Influenza virus\n",
        "C) Parainfluenza virus\n",
        "D) Adenovirus\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "print(\"Test Prompt:\")\n",
        "print(test_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBdaQLbBgrdf"
      },
      "source": [
        "## Task: Generate a Response from a Fine Tuned Language Model\n",
        "\n",
        "**Goal:** Write code that takes a text prompt, generates a response from the model, and prints the final answer.\n",
        "\n",
        "### Steps to complete\n",
        "1. Prepare the input  \n",
        "   - Take a test prompt  \n",
        "   - Convert the text into model readable form using the tokenizer  \n",
        "   - Move the input to the same device as the model  \n",
        "\n",
        "2. Run generation safely  \n",
        "   - Turn off gradient calculation  \n",
        "   - Ask the model to generate new text based on the input  \n",
        "\n",
        "3. Control the output  \n",
        "   - Limit how long the generated response can be  \n",
        "   - Use a simple and stable decoding method  \n",
        "   - Handle padding correctly so generation does not fail  \n",
        "\n",
        "4. Decode the result  \n",
        "   - Convert generated tokens back into readable text  \n",
        "   - Remove any special tokens  \n",
        "\n",
        "5. Display the response  \n",
        "   - Print a clear heading  \n",
        "   - Show only the final model answer in a clean format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1gFfUGAgrdf"
      },
      "source": [
        "## REMOVE THIS BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbFDzWfDU66V"
      },
      "outputs": [],
      "source": [
        "# Generate response\n",
        "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=200,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINE-TUNED MODEL RESPONSE\")\n",
        "print(\"=\" * 80)\n",
        "print(response.split(\"### Response:\")[1] if \"### Response:\" in response else response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gToXEtRvgrdf"
      },
      "source": [
        "### Visualizing Training Progress\n",
        "\n",
        "Plotting the training loss over time helps us:\n",
        "- Verify the model is learning (loss should decrease)\n",
        "- Check for overfitting (validation loss increasing while training loss decreases)\n",
        "- Identify if we need more/fewer training steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9kycsNNU8EJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get training history\n",
        "history = trainer.state.log_history\n",
        "\n",
        "# Extract loss values\n",
        "train_losses = [(h['step'], h['loss']) for h in history if 'loss' in h]\n",
        "eval_losses = [(h['step'], h['eval_loss']) for h in history if 'eval_loss' in h]\n",
        "\n",
        "if train_losses:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot training loss\n",
        "    steps, losses = zip(*train_losses)\n",
        "    plt.plot(steps, losses, label='Training Loss', color='blue', alpha=0.7)\n",
        "\n",
        "    # Plot evaluation loss if available\n",
        "    if eval_losses:\n",
        "        eval_steps, eval_loss_vals = zip(*eval_losses)\n",
        "        plt.plot(eval_steps, eval_loss_vals, label='Validation Loss', color='red', marker='o')\n",
        "\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No training history available for plotting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrPVSyKIgrdf"
      },
      "source": [
        "\n",
        "# PART 11: Model Evaluation\n",
        "\n",
        "Setup for Comprehensive Evaluation\n",
        "\n",
        "In this section, we'll:\n",
        "1. Load both the base model and fine-tuned model\n",
        "2. Compare their performance side-by-side\n",
        "3. Analyze results across different medical subjects\n",
        "4. Visualize improvements\n",
        "\n",
        "This helps us quantify the benefit of fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w6gfkQ_o3Qe"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxOIOCMJVBOH",
        "outputId": "28ae28f0-8bb5-4c63-ed13-c92458c1ce46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "from datasets import load_from_disk, load_dataset\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1MtgUbBgrdf"
      },
      "source": [
        "### Configuration for Evaluation\n",
        "\n",
        "We set up:\n",
        "- **Model paths**: Where to find the base model and our trained adapter\n",
        "- **Evaluation size**: Number of examples to test (50 for tutorial; increase for thorough evaluation)\n",
        "- **Generation length**: Maximum tokens to generate per answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PoqgyrtVCzt",
        "outputId": "2c5d8f8a-83d7-4cf7-c9fa-f3ac9a86ac09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base model: unsloth/Llama-3.2-1B\n",
            "Adapter path: ./medical_llm_finetuned/final_adapter\n"
          ]
        }
      ],
      "source": [
        "# Model paths - adjust if you saved elsewhere\n",
        "BASE_MODEL_ID = \"unsloth/Llama-3.2-1B\"\n",
        "ADAPTER_PATH = \"./medical_llm_finetuned/final_adapter\"\n",
        "\n",
        "# Evaluation settings\n",
        "NUM_EVAL_SAMPLES = 50  # Number of samples for evaluation (keep small for tutorial)\n",
        "MAX_NEW_TOKENS = 150\n",
        "\n",
        "print(f\"Base model: {BASE_MODEL_ID}\")\n",
        "print(f\"Adapter path: {ADAPTER_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ8JNeDkocf2"
      },
      "source": [
        "Download the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lkc50zHogwP",
        "outputId": "94518bb0-e4fc-42e8-d6ca-dcaeb7bce554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YlwkPvBraIeAnJxLPDV8fPzl-Co0Hj6y\n",
            "From (redirected): https://drive.google.com/uc?id=1YlwkPvBraIeAnJxLPDV8fPzl-Co0Hj6y&confirm=t&uuid=73303e39-a3bf-4d0f-ad0d-11ad96bf483c\n",
            "To: /content/MedMCQA-Collab-Checkpoint.zip\n",
            "100% 40.6M/40.6M [00:00<00:00, 82.5MB/s]\n",
            "Archive:  /content/MedMCQA-Collab-Checkpoint.zip\n",
            "replace MedMCQA-Collab-Checkpoint/adapter_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace MedMCQA-Collab-Checkpoint/adapter_model.safetensors? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: MedMCQA-Collab-Checkpoint/adapter_model.safetensors  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/optimizer.pt  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/README.md  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/rng_state_0.pth  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/rng_state_1.pth  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/rng_state_2.pth  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/rng_state_3.pth  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/scheduler.pt  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/special_tokens_map.json  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/tokenizer.json  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/tokenizer_config.json  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/trainer_state.json  \n",
            "  inflating: MedMCQA-Collab-Checkpoint/training_args.bin  \n"
          ]
        }
      ],
      "source": [
        "!gdown 1YlwkPvBraIeAnJxLPDV8fPzl-Co0Hj6y\n",
        "!unzip /content/MedMCQA-Collab-Checkpoint.zip\n",
        "ADAPTER_PATH = \"./MedMCQA-Collab-Checkpoint/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOaffhKCpZct"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm3SbPjngrdg"
      },
      "source": [
        "# Part 12: Loading Models for Comparison\n",
        "\n",
        "### Setting Up Quantization\n",
        "\n",
        "We use the same 4-bit quantization as during training for consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PWbSP6gVD1E"
      },
      "outputs": [],
      "source": [
        "# Quantization config (same as training)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbn45sdegrdg"
      },
      "source": [
        "### Loading the Base Model\n",
        "\n",
        "This is the original, unmodified model before fine-tuning. We'll compare its performance against our fine-tuned version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkfY7MuBVE67",
        "outputId": "418fbdbb-e1a5-47a0-f60d-5e14cff13c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer loaded\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"Tokenizer loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VepPaY9Qgrdg"
      },
      "source": [
        "### Loading the Fine-Tuned Model\n",
        "\n",
        "We load our trained LoRA adapter on top of the base model. The adapter modifies the model's behavior based on our medical training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "0802ed9f7e264ee580adaf3c3510da14",
            "5c13c934337144d784c1b0612c23173d",
            "1ec69db623d64d5a90162f61d16cfe22",
            "88ae3d1c40974b2596511340d8b968b4",
            "fc55a9096344479c9046cb3bf1af1e1a",
            "f8b7967ad5774ffa899762e5e8821f65",
            "5a3c8f62333745958dd2b7fc9a4d97b0",
            "998216b95aa44e5cbee854e43f667c51",
            "5899459e8cb349ce89aa70cb478145cd",
            "d3c8e68048ed45aeb7dbab38bcb3996d",
            "07286d26e1ae4630af17a3d229a1e34d",
            "eba0333843a04336a5f03abea1a07f06",
            "cf5437b6df9943119d0ec498219bca19",
            "ae4e7011398342368bc16fd55954734b",
            "00b3a2c8e90047fabf3a57ac8e9a9a0b",
            "e716f28ac9224bbfb61fc8135f85ae8c",
            "6526e18414ac49609bcbcc56e63a20cf",
            "ab2a6bd12f3348dbad26b5c53117fbdc",
            "7c8c64f562b2478d9d684fd1f01574fc",
            "26ad59baf42343d1bbcbee9575bc808e",
            "6a452d72fb1d4ee4bc39e91d816a53d1",
            "b5f90946e1984339a4394b29fcf5467d"
          ]
        },
        "id": "QcymqqIfVGAH",
        "outputId": "80bb7f72-4a0a-45bd-cee6-279ef5dde0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading base model: unsloth/Llama-3.2-1B\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0802ed9f7e264ee580adaf3c3510da14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eba0333843a04336a5f03abea1a07f06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load base model\n",
        "print(f\"Loading base model: {BASE_MODEL_ID}\")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTyibg8jgrdg"
      },
      "source": [
        "### Preparing Test Data\n",
        "\n",
        "We load fresh test data from MedMCQA's validation set:\n",
        "- Use examples the model hasn't seen during training\n",
        "- Format them consistently with training data\n",
        "- Extract ground truth answers for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328,
          "referenced_widgets": [
            "865d31d1d07641c2959532bde9d8fb55",
            "84de363856054b4784a0b923d10466d7",
            "1d3de473a5874ba6aa941635da008ad4",
            "19d9ec607e6c4c198e7a67cd646c4524",
            "9f85361550154325869c0a0560339933",
            "a97db9684633465d872b8a1546292068",
            "f081433133a64c0a84c581648bab7b7b",
            "b5041dc8acdb49f790915cb3fb45e878",
            "9c66ff70150846a1b091e5157d1e6eca",
            "ac3243de5e9d4736ad7281c3131c9061",
            "71b4471e2d624fae9308e0e7ac3252a7",
            "1cfe28de38594dfdb74e109335f33951",
            "74bc9d6ebebe45e499e2b7173d747a9f",
            "74ca7b0d542c451093e7bc057e6d0209",
            "b65f3d53219e4ece927d4d49584b1a67",
            "dda5bf1bd5344064b4f93373e1ea0eef",
            "cf9b8eab54a74bb08abbc0e03fb8adf8",
            "9822f5407d7f4f16a052dd489f023908",
            "22fa35dc64d5445b85c3e5b02fc4297f",
            "f4230c3e8645449182271c0e7d08af12",
            "248f0e0eb13e41f59b0835cb39c92c4e",
            "62ec8ad9440245f3848bd498dbf2687c",
            "4e8f9ac4b0f4401fb3ca396b8c7ed389",
            "db3e67d2393648eb8a5336f1136097dd",
            "609431c6fa5a4f289253a7488cc34665",
            "7ac13e9714aa46aa9de2bcb0eaaafe13",
            "d9e0642afe5e42249a5e207745fcf407",
            "e74ed699665d4f71ac6b06cf3932923b",
            "e173c3337a5a41a4b714a5101fc1c821",
            "4d863c12d6404071bad8dea446d10900",
            "542f954119614d42b33f35ae064613e3",
            "bef1f604436945e6bea7bf95fecefbbc",
            "b849309de6ea4d7a875a7324e0465229",
            "7221019f436945dbae5e42c09c3e9b8b",
            "52e908813fd24b019b5717bf98b9bd5a",
            "64669c74b86b4ef6af4c18c72b7e78fb",
            "aad2cb1613ce4eeabc8ada5d0a089d50",
            "3fa77d19f9e445cb94fad2ae72c52e34",
            "a456e4fe24b24baabd063c2bf7dff5e6",
            "1d113ef14b9244528012f849fe3ac4f0",
            "899cd14d1e3c4fe09651df1ccf2d56c1",
            "f9b8e68197fb4d03b8324eab8b07d890",
            "6082206484f342d3a49dad9a6b29c0c4",
            "b45d429fb9d3496c9d100dca887dfdd5",
            "dd31f5ab14894978afda826859ad1fa2",
            "79690fcab1d54487aad96a9f09726aed",
            "d4d5c3036d33407cb3b1900440aab7a8",
            "481b228bf0f143f7ab04a1d2ec489147",
            "eb203833dc8a48f3b660dceb1f1adca1",
            "892fefde024a4eab9dd4bf4734f55ab6",
            "d557ffdb4d1547c1b6d259e2f01b1acb",
            "d2b412f853d44efba481a560bb685fa3",
            "0459724541cb4abcb9c5d89d7f8a22a0",
            "751c89c7b2f542b6ad48504e0fe2dd74",
            "faf78f318f5945ae973ca9a3869a369e",
            "4be9b69b9f8542ca8496bf72a803a715",
            "de3c79caa98749e5bee86810d744fc30",
            "0df7725ee21f4ea2a0c08096a786ff95",
            "0d98c42f303e45519a38d45b02b7b788",
            "e5e1408e008040c9a35dcf992847e3de",
            "9ac135d1ab3647c08f4e73dec77361f7",
            "d1017b61cf87473db2f0402f757dca6d",
            "1dc5e8ba4114478caa9707a109a41b41",
            "7006fd8f18d6451d89fdbd08de473835",
            "03abb3b638654def95ae7af5471c0bc0",
            "39a6199fa846407cac2c4bfe8f84f289",
            "e4a1b456c6774c648d7387a8ca209af4",
            "879dc52623454fca8d0ea10eaab7d376",
            "b7043d4417e74192a59e9338b029c1ea",
            "a2190d4c8a8247c68683b1b35332abed",
            "ce17332596954ea594ef12a253393448",
            "f8bf2c0f71894684ba49387eeee68f84",
            "c4617834f9c848f096dd57ae29696a82",
            "f47d60b1b6e3491798d3b945d0545681",
            "8d04acb553714d31af5fa3fecce3c632",
            "c6f0c5a5937f499094e8cfa11ba95348",
            "0bd879ce1ac948a2809b871c9705fc5e",
            "c1e7eecc35414c90ae5b98957c6bdce5",
            "411d3bbd8c1245b4952526110cd1a9dc",
            "a10eef411a2a4c28906213c580f44f50",
            "f75a0b078ff14d20ad8e379c7eb8d09a",
            "7b7cea93605e43ada08cb62df997359e",
            "3e760193293c48d4915ac8fa2c4bb06b",
            "71cf4adbd90b48e683fbffb1330ca0e6",
            "d241abed062d4d70bc3786b4da6104f4",
            "e2e6e3fde244425b9647009e007fabdf",
            "c9ae32ad9a63427487826b85355998d4",
            "4eb5acde0f5245e7b3da6b3a996ceffe"
          ]
        },
        "id": "qDx-ItqVVIKb",
        "outputId": "59580ddb-475d-4ff3-cf49-3d46b6d46b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MedMCQA test data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "865d31d1d07641c2959532bde9d8fb55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cfe28de38594dfdb74e109335f33951",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/85.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e8f9ac4b0f4401fb3ca396b8c7ed389",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/936k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7221019f436945dbae5e42c09c3e9b8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/validation-00000-of-00001.parquet:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd31f5ab14894978afda826859ad1fa2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/182822 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4be9b69b9f8542ca8496bf72a803a715",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/6150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4a1b456c6774c648d7387a8ca209af4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/4183 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e7eecc35414c90ae5b98957c6bdce5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test data loaded: 50 samples\n"
          ]
        }
      ],
      "source": [
        "# Load MedMCQA for evaluation\n",
        "print(\"Loading MedMCQA test data...\")\n",
        "\n",
        "raw_dataset = load_dataset(\"openlifescienceai/medmcqa\")\n",
        "\n",
        "def format_for_eval(example):\n",
        "    instruction = \"You are a medical expert. Answer the following multiple-choice medical question. Choose the correct option and provide a brief explanation.\"\n",
        "    options = f\"A) {example['opa']}\\nB) {example['opb']}\\nC) {example['opc']}\\nD) {example['opd']}\"\n",
        "    input_text = f\"Question: {example['question']}\\n\\nOptions:\\n{options}\"\n",
        "\n",
        "    answer_labels = ['A', 'B', 'C', 'D']\n",
        "    correct_answer = answer_labels[example['cop']]\n",
        "\n",
        "    prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n\"\n",
        "\n",
        "    return {\n",
        "        'prompt': prompt,\n",
        "        'correct_answer': correct_answer,\n",
        "        'question': example['question'],\n",
        "        'subject': example['subject_name']\n",
        "    }\n",
        "\n",
        "test_data = raw_dataset['validation'].shuffle(seed=42).select(range(NUM_EVAL_SAMPLES)).map(format_for_eval)\n",
        "\n",
        "print(f\"\\nTest data loaded: {len(test_data)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAvT82BDgrdg"
      },
      "source": [
        "# Part 13: Evaluation Functions\n",
        "\n",
        "### Helper Functions for Evaluation\n",
        "\n",
        "We define three key functions:\n",
        "\n",
        "1. **generate_response()**: Generates answers from the model\n",
        "   - Uses low temperature (0.1) for consistent, factual answers\n",
        "   - Handles tokenization and decoding\n",
        "\n",
        "2. **extract_answer()**: Parses model output to find the answer letter\n",
        "   - Uses regex patterns to find \"The answer is B\" or similar\n",
        "   - Falls back to finding first A/B/C/D in response\n",
        "   - Returns None if no answer found\n",
        "\n",
        "3. **evaluate_model()**: Runs full evaluation pipeline\n",
        "   - Tests model on all examples\n",
        "   - Compares predictions to ground truth\n",
        "   - Calculates accuracy and stores results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_eIhh9egrdg"
      },
      "source": [
        "# Task: Implement and Evaluate an MCQ Answering Model\n",
        "\n",
        "## Objective\n",
        "In this task, you will build a simple evaluation pipeline to test how well a language model answers multiple choice questions. You will generate answers, extract the chosen option, and compute accuracy on a test dataset.\n",
        "\n",
        "## Functions You Need to Write\n",
        "\n",
        "You must implement the following three functions:\n",
        "\n",
        "1. `generate_response`\n",
        "2. `extract_answer`\n",
        "3. `evaluate_model`\n",
        "\n",
        "## Task Description with Hints\n",
        "\n",
        "### 1. `generate_response`\n",
        "\n",
        "**What to do**\n",
        "- Write a function that takes a model, tokenizer, and a text prompt\n",
        "- Convert the prompt into tensors using the tokenizer\n",
        "- Move inputs to the same device as the model\n",
        "- Run the model only in inference mode\n",
        "- Generate a text response\n",
        "- Decode the output tokens into a readable string\n",
        "- Return the cleaned response text\n",
        "\n",
        "**Hints**\n",
        "- Disable gradient computation during generation\n",
        "- Use the tokenizer to handle truncation for long prompts\n",
        "- Decode only the newly generated tokens, not the input prompt\n",
        "- Remove special tokens from the final output\n",
        "\n",
        "### 2. `extract_answer`\n",
        "\n",
        "**What to do**\n",
        "- Write a function that takes the model’s text response\n",
        "- Try to find the selected option letter from the response\n",
        "- Handle common formats like:\n",
        "  - “The correct answer is B”\n",
        "  - “Answer is C”\n",
        "  - “A) option text”\n",
        "- Return a single capital letter representing the option\n",
        "- If nothing is found, return an empty or null value\n",
        "\n",
        "**Hints**\n",
        "- Regular expressions are very useful here\n",
        "- Search patterns in a priority order, from most specific to most general\n",
        "- As a fallback, scan the beginning of the response for option letters\n",
        "- Always convert the final answer to uppercase\n",
        "\n",
        "\n",
        "### 3. `evaluate_model`\n",
        "\n",
        "**What to do**\n",
        "- Write a function that takes a model, tokenizer, and test dataset\n",
        "- Loop over all examples in the dataset\n",
        "- For each example:\n",
        "  - Build the prompt\n",
        "  - Generate a response using `generate_response`\n",
        "  - Extract the predicted option using `extract_answer`\n",
        "  - Compare it with the correct answer\n",
        "- Count total questions and correct predictions\n",
        "- Compute and print the final accuracy\n",
        "- Store per question results for later inspection\n",
        "\n",
        "**Hints**\n",
        "- Use a progress bar to track evaluation progress\n",
        "- Keep counters for correct and total predictions\n",
        "- Store both the model response and extracted answer for debugging\n",
        "- Handle cases where the model fails to produce a valid option\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtptEr1Wgrdg"
      },
      "source": [
        "REMOVE THIS CODE BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0BZGSIlVJW6"
      },
      "outputs": [],
      "source": [
        "def generate_response(model, tokenizer, prompt, max_new_tokens=150):\n",
        "    \"\"\"\n",
        "    Generate a response from the model.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "\n",
        "def extract_answer(response):\n",
        "    \"\"\"\n",
        "    Extract the answer letter (A, B, C, or D) from the model's response.\n",
        "    \"\"\"\n",
        "    patterns = [\n",
        "        r'correct answer is\\s*([A-Da-d])',\n",
        "        r'answer is\\s*([A-Da-d])',\n",
        "        r'^\\s*([A-Da-d])\\)',\n",
        "        r'^\\s*([A-Da-d])\\s',\n",
        "        r'\\b([A-Da-d])\\)\\s',\n",
        "        r'Option\\s*([A-Da-d])',\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, response, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group(1).upper()\n",
        "\n",
        "    for char in response[:50]:  # Check first 50 chars\n",
        "        if char.upper() in ['A', 'B', 'C', 'D']:\n",
        "            return char.upper()\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def evaluate_model(model, tokenizer, test_data, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Evaluate model accuracy on test data.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    results = []\n",
        "\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "    for example in tqdm(test_data, desc=model_name):\n",
        "        prompt = example['prompt']\n",
        "        correct_answer = example['correct_answer']\n",
        "\n",
        "        response = generate_response(model, tokenizer, prompt)\n",
        "        predicted = extract_answer(response)\n",
        "\n",
        "        is_correct = predicted == correct_answer\n",
        "        if is_correct:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "        results.append({\n",
        "            'question': example['question'][:100],\n",
        "            'subject': example['subject'],\n",
        "            'correct_answer': correct_answer,\n",
        "            'predicted': predicted,\n",
        "            'is_correct': is_correct,\n",
        "            'response': response[:200]\n",
        "        })\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    print(f\"\\n{model_name} Accuracy: {accuracy:.2%} ({correct}/{total})\")\n",
        "\n",
        "    return accuracy, pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmYAvg3Agrdh"
      },
      "source": [
        "# Part 14: Quantitative Evaluation\n",
        "\n",
        "### Running Full Evaluation\n",
        "\n",
        "Now we systematically evaluate both models on all test examples. This will take a few minutes.\n",
        "\n",
        "The progress bar shows evaluation progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2NOj_bTVMKU",
        "outputId": "d8afaad8-3785-4ad2-9afc-9da356bd5ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting evaluation (this will take a few minutes)...\n",
            "\n",
            "Evaluating Base Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Base Model:   0%|          | 0/50 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Base Model: 100%|██████████| 50/50 [06:23<00:00,  7.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Base Model Accuracy: 26.00% (13/50)\n"
          ]
        }
      ],
      "source": [
        "# Evaluate base model\n",
        "print(\"Starting evaluation (this will take a few minutes)...\")\n",
        "base_accuracy, base_results = evaluate_model(base_model, tokenizer, test_data, \"Base Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuH4DQILVG-2",
        "outputId": "afc77f3e-8107-40f7-94b0-5492f300eedb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading fine-tuned adapter from: ./MedMCQA-Collab-Checkpoint/\n",
            "Fine-tuned model loaded\n"
          ]
        }
      ],
      "source": [
        "# Load fine-tuned model (base + adapter)\n",
        "print(f\"Loading fine-tuned adapter from: {ADAPTER_PATH}\")\n",
        "\n",
        "try:\n",
        "    # Load the adapter on top of the base model\n",
        "    finetuned_model = PeftModel.from_pretrained(\n",
        "        base_model,\n",
        "        ADAPTER_PATH,\n",
        "        is_trainable=False,\n",
        "    )\n",
        "    print(\"Fine-tuned model loaded\")\n",
        "    HAS_FINETUNED = True\n",
        "except Exception as e:\n",
        "    print(f\"Could not load adapter: {e}\")\n",
        "    print(\"Using base model only for demonstration.\")\n",
        "    finetuned_model = None\n",
        "    HAS_FINETUNED = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwUruxDwVNG1",
        "outputId": "4d1d6119-4726-4b4c-b1ed-6fd1895de989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Fine-tuned Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fine-tuned Model: 100%|██████████| 50/50 [03:57<00:00,  4.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fine-tuned Model Accuracy: 52.00% (26/50)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate fine-tuned model\n",
        "if HAS_FINETUNED:\n",
        "    ft_accuracy, ft_results = evaluate_model(finetuned_model, tokenizer, test_data, \"Fine-tuned Model\")\n",
        "else:\n",
        "    ft_accuracy = None\n",
        "    ft_results = None\n",
        "    print(\"Skipping fine-tuned model evaluation (adapter not loaded)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqKMRrhfVOEL",
        "outputId": "0058ae31-771d-443e-cc40-c2b95f91c738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "\n",
            "Model                    Accuracy    Correct\n",
            "--------------------------------------------\n",
            "Base Model                 26.00%         13/50\n",
            "Fine-tuned Model           52.00%         26/50\n",
            "\n",
            "--------------------------------------------\n",
            "Improvement: +26.00% (13 more correct)\n"
          ]
        }
      ],
      "source": [
        "# Results comparison\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\n{'Model':<20} {'Accuracy':>12} {'Correct':>10}\")\n",
        "print(\"-\" * 44)\n",
        "print(f\"{'Base Model':<20} {base_accuracy:>12.2%} {base_results['is_correct'].sum():>10}/{len(base_results)}\")\n",
        "\n",
        "if ft_accuracy is not None:\n",
        "    print(f\"{'Fine-tuned Model':<20} {ft_accuracy:>12.2%} {ft_results['is_correct'].sum():>10}/{len(ft_results)}\")\n",
        "    print(\"\\n\" + \"-\" * 44)\n",
        "    improvement = ft_accuracy - base_accuracy\n",
        "    print(f\"Improvement: {improvement:+.2%} ({improvement * len(test_data):.0f} more correct)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1AVH65Hgrdh"
      },
      "source": [
        "## Part 18: PubMedQA Evaluation\n",
        "\n",
        "### Setting Up PubMedQA Test Data\n",
        "\n",
        "We prepare test data for evaluating the PubMedQA-finetuned model. PubMedQA requires yes/no/maybe classification based on research abstracts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291,
          "referenced_widgets": [
            "4daa2ede459a4c99a216647e54a3f4de",
            "2ac9cdff37564c33ba13776f4e66f703",
            "855b3304e3b8403b9e91a38f9c8f5e50",
            "878c0faa3fd2436fb51e9b90ec2dcad0",
            "d29480e9162e4e9f92d76cebc315575c",
            "a6572713305040bbb209c1516f31b293",
            "a435e25655104fac9faf86aaa8281641",
            "4f414020e76e41599f48987a0a2cdcaf",
            "e9b081dccb984009bacec2bb22f1c7f7",
            "38405a34a3a847158629dc53a44a6126",
            "a08b50178479484c8dbab6781ca4d335",
            "b115c0de6a15454583a5c240c412c854",
            "4c90df0bfcc84d43bd858beefa0739c9",
            "647d314157d148e2bbb5f7175fee0018",
            "ab310a12274041869b6c9806df03f49e",
            "4835d76f9bdd487bab47f02a35c01700",
            "e6b08aaacdca44a6847d17fbb6268e3b",
            "791e18568bb8484cacafdb36f4c3762c",
            "cf171f8ff6a14d28a5f3050d12b84d08",
            "c4787f79b78c4b338206ea4fd9439e7c",
            "6b13d52938f546c0b5c8223c799ccf12",
            "a14120e822b64ac8b690534374a2d3a3",
            "24158f9c09214035bea33bafa84c601d",
            "16388c3aebfb465d8d2f67ff8ca8634d",
            "21a5d7ebfc744a66aa6c593a49f9584f",
            "6b051c9750744616848b342bbf412b93",
            "f1d5eaf573094405b4edb9223ea2febf",
            "7a19773f6a1a483da6bd354eae410a59",
            "07a3348d8e5d468f865000434bd8bb09",
            "ece3681a37f54828a618f2cf3c3b3dbf",
            "0085742b2d9d42ba802ba6ea9713f144",
            "ec7d3a15516144008e955972ddc5a117",
            "64d3ced5a1e0489897733d0119a83460",
            "6940c7e5bfe64a05aeff79b0cae7798b",
            "f994665e0c8544f7a58023a02a115e17",
            "6be9a21a7add423c82e6768d8024def0",
            "52ad538d6a154b79ab7e343fdc2bcd99",
            "8674ae90863b4e6bb2783c8488fd6b21",
            "84306a6cbb8a441a9d6f005be6c13e55",
            "3c6ca45699214de8934a376e42c97dc8",
            "5bcecbaefed54c929e236b3caecdb022",
            "79255675012a4137aed1403173b2b004",
            "a275ac5f3b8445cb82052903a5670971",
            "fac032f5eaf94f5fa7fb4ecba8c99350"
          ]
        },
        "id": "GnXdC6lHgrdh",
        "outputId": "c70a27ed-1155-42e9-94c5-7a3174205f11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'qiaojin/PubMedQA' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'qiaojin/PubMedQA' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading PubMedQA test data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4daa2ede459a4c99a216647e54a3f4de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b115c0de6a15454583a5c240c412c854",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pqa_labeled/train-00000-of-00001.parquet:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24158f9c09214035bea33bafa84c601d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6940c7e5bfe64a05aeff79b0cae7798b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PubMedQA test data loaded: 50 samples\n"
          ]
        }
      ],
      "source": [
        "# Load PubMedQA test data\n",
        "PUBMEDQA_EVAL_SAMPLES = 50\n",
        "\n",
        "print(\"Loading PubMedQA test data...\")\n",
        "\n",
        "raw_pubmedqa = load_dataset(\"qiaojin/PubMedQA\", \"pqa_labeled\", trust_remote_code=True)\n",
        "\n",
        "def format_pubmedqa_for_eval(example):\n",
        "    contexts = example['context']['contexts'] if example['context']['contexts'] else []\n",
        "    context = \" \".join(contexts) if contexts else \"No context provided.\"\n",
        "\n",
        "    instruction = \"You are a medical expert. Based on the provided research context, answer the following yes/no/maybe question. Provide a brief explanation for your answer.\"\n",
        "    input_text = f\"Context: {context}\\n\\nQuestion: {example['question']}\"\n",
        "\n",
        "    prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n\"\n",
        "\n",
        "    return {\n",
        "        'prompt': prompt,\n",
        "        'correct_answer': example['final_decision'],\n",
        "        'question': example['question']\n",
        "    }\n",
        "\n",
        "pubmedqa_test_data = raw_pubmedqa['train'].shuffle(seed=123).select(range(PUBMEDQA_EVAL_SAMPLES)).map(format_pubmedqa_for_eval)\n",
        "\n",
        "print(f\"PubMedQA test data loaded: {len(pubmedqa_test_data)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S80x3wkcgrdh"
      },
      "source": [
        "### Loading PubMedQA Fine-Tuned Model for Evaluation\n",
        "\n",
        "We load the PubMedQA adapter to compare its performance against the base model on biomedical yes/no/maybe questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChusRYGZr9Te"
      },
      "outputs": [],
      "source": [
        "# Load PubMedQA fine-tuned model\n",
        "PUBMEDQA_ADAPTER_PATH = \"./pubmedqa_llm_finetuned/final_adapter\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MHgrDSr97u",
        "outputId": "62d97476-4178-44f0-9250-ae8add10708e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hz7G8ZCmSH_NOpeStJxtHLBueJSwcExE\n",
            "To: /content/PUBMEDQA-Collab-Checkpoint.zip\n",
            "100% 11.5M/11.5M [00:00<00:00, 48.4MB/s]\n",
            "Archive:  /content/PUBMEDQA-Collab-Checkpoint.zip\n",
            "replace PUBMEDQA-Collab-Checkpoint/adapter_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!gdown 1Hz7G8ZCmSH_NOpeStJxtHLBueJSwcExE\n",
        "!unzip /content/PUBMEDQA-Collab-Checkpoint.zip\n",
        "PUBMEDQA_ADAPTER_PATH = \"./PUBMEDQA-Collab-Checkpoint/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImO3M5V_grdh",
        "outputId": "d0a233aa-6ba9-4c58-8817-79082386ca4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading PubMedQA adapter from: ./PUBMEDQA-Collab-Checkpoint/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PubMedQA fine-tuned model loaded\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loading PubMedQA adapter from: {PUBMEDQA_ADAPTER_PATH}\")\n",
        "\n",
        "try:\n",
        "    pubmedqa_finetuned_model = PeftModel.from_pretrained(\n",
        "        base_model,\n",
        "        PUBMEDQA_ADAPTER_PATH,\n",
        "        is_trainable=False,\n",
        "    )\n",
        "    print(\"PubMedQA fine-tuned model loaded\")\n",
        "    HAS_PUBMEDQA_FINETUNED = True\n",
        "except Exception as e:\n",
        "    print(f\"Could not load PubMedQA adapter: {e}\")\n",
        "    print(\"Skipping PubMedQA fine-tuned model evaluation.\")\n",
        "    pubmedqa_finetuned_model = None\n",
        "    HAS_PUBMEDQA_FINETUNED = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBlwvymMgrdh"
      },
      "source": [
        "### PubMedQA Evaluation Functions\n",
        "\n",
        "We define helper functions for extracting yes/no/maybe answers and evaluating the model on PubMedQA test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Wd7CCNgrdi"
      },
      "source": [
        "# Task: Extract PubMedQA Evaluation Answer\n",
        "\n",
        "## Objective\n",
        "Write a function to extract a **yes**, **no**, or **maybe** label from a model’s text output for evaluation.\n",
        "\n",
        "## Function to Implement\n",
        "- `extract_pubmedqa_eval_answer`\n",
        "\n",
        "## Task Description\n",
        "\n",
        "Write a function that:\n",
        "- Takes the model response as input\n",
        "- Normalizes the text by converting it to lowercase and trimming spaces\n",
        "- Detects whether the answer is **yes**, **no**, or **maybe**\n",
        "- Returns the detected label\n",
        "- Returns nothing meaningful if no clear answer is found\n",
        "\n",
        "## Hints\n",
        "- First check if the response starts with **yes**, **no**, or **maybe**\n",
        "- If not, scan only the beginning of the response\n",
        "- Look for common patterns like `yes.` `yes,` `no.` `no,` or `maybe`\n",
        "- Keep the logic simple and deterministic\n",
        "\n",
        "## Expected Outcome\n",
        "You will be able to convert free text model outputs into standardized PubMedQA labels for evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdX4yyPtgrdi"
      },
      "source": [
        "REMOVE THE EXTRACT PUBMEDQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGDD0L1egrdi"
      },
      "outputs": [],
      "source": [
        "def extract_pubmedqa_eval_answer(response):\n",
        "    \"\"\"Extract yes/no/maybe answer from model output for evaluation.\"\"\"\n",
        "    response_lower = response.lower().strip()\n",
        "\n",
        "    # Check explicit patterns\n",
        "    if response_lower.startswith('yes'):\n",
        "        return 'yes'\n",
        "    elif response_lower.startswith('no'):\n",
        "        return 'no'\n",
        "    elif response_lower.startswith('maybe'):\n",
        "        return 'maybe'\n",
        "\n",
        "    # Check within first 100 characters\n",
        "    first_part = response_lower[:100]\n",
        "    if 'yes.' in first_part or 'yes,' in first_part:\n",
        "        return 'yes'\n",
        "    elif 'no.' in first_part or 'no,' in first_part:\n",
        "        return 'no'\n",
        "    elif 'maybe' in first_part:\n",
        "        return 'maybe'\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def evaluate_pubmedqa_model(model, tokenizer, test_data, model_name=\"Model\"):\n",
        "    \"\"\"Evaluate model on PubMedQA test data.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    results = []\n",
        "\n",
        "    print(f\"\\nEvaluating {model_name} on PubMedQA...\")\n",
        "\n",
        "    for example in tqdm(test_data, desc=model_name):\n",
        "        prompt = example['prompt']\n",
        "        correct_answer = example['correct_answer']\n",
        "\n",
        "        response = generate_response(model, tokenizer, prompt, max_new_tokens=150)\n",
        "        predicted = extract_pubmedqa_eval_answer(response)\n",
        "\n",
        "        is_correct = predicted == correct_answer\n",
        "        if is_correct:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "        results.append({\n",
        "            'question': example['question'][:100],\n",
        "            'correct_answer': correct_answer,\n",
        "            'predicted': predicted,\n",
        "            'is_correct': is_correct,\n",
        "            'response': response[:200]\n",
        "        })\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    print(f\"\\n{model_name} PubMedQA Accuracy: {accuracy:.2%} ({correct}/{total})\")\n",
        "\n",
        "    return accuracy, pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWeeO48ygrdi"
      },
      "source": [
        "### Running PubMedQA Evaluation\n",
        "\n",
        "We evaluate both the base model and the PubMedQA fine-tuned model on the test set to measure the improvement from fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfWQCiI1grdi",
        "outputId": "17f3d98b-6593-430e-f327-df2c97c2382a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading base model: unsloth/Llama-3.2-1B\n"
          ]
        }
      ],
      "source": [
        "# Load base model\n",
        "print(f\"Loading base model: {BASE_MODEL_ID}\")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "urHdQdrJgrdi",
        "outputId": "bf00852b-55c4-49fe-b7b5-a21c99851d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating base model on PubMedQA...\n",
            "\n",
            "Evaluating Base Model on PubMedQA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Base Model: 100%|██████████| 50/50 [04:13<00:00,  5.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Base Model PubMedQA Accuracy: 40.00% (20/50)\n",
            "\n",
            "Evaluating PubMedQA Fine-tuned Model on PubMedQA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PubMedQA Fine-tuned Model: 100%|██████████| 50/50 [02:43<00:00,  3.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PubMedQA Fine-tuned Model PubMedQA Accuracy: 82.00% (41/50)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate base model on PubMedQA\n",
        "print(\"Evaluating base model on PubMedQA...\")\n",
        "pubmedqa_base_accuracy, pubmedqa_base_results = evaluate_pubmedqa_model(\n",
        "    base_model, tokenizer, pubmedqa_test_data, \"Base Model\"\n",
        ")\n",
        "\n",
        "# Evaluate fine-tuned model on PubMedQA\n",
        "if HAS_PUBMEDQA_FINETUNED:\n",
        "    pubmedqa_ft_accuracy, pubmedqa_ft_results = evaluate_pubmedqa_model(\n",
        "        pubmedqa_finetuned_model, tokenizer, pubmedqa_test_data, \"PubMedQA Fine-tuned Model\"\n",
        "    )\n",
        "else:\n",
        "    pubmedqa_ft_accuracy = None\n",
        "    pubmedqa_ft_results = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK2feTTUgrdi"
      },
      "source": [
        "### PubMedQA Results Summary\n",
        "\n",
        "We compare the base model and fine-tuned model performance on PubMedQA. The random baseline for 3-class classification (yes/no/maybe) is 33.3%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys3tBqyxgrdi",
        "outputId": "9d707409-36ed-42f9-fa4c-ba2e37f6c357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "PUBMEDQA EVALUATION RESULTS\n",
            "==================================================\n",
            "\n",
            "Model                         Accuracy    Correct\n",
            "--------------------------------------------------\n",
            "Base Model                      40.00%         20/50\n",
            "PubMedQA Fine-tuned             82.00%         41/50\n",
            "\n",
            "--------------------------------------------------\n",
            "Improvement: +42.00%\n",
            "Random baseline: 33.3% (yes/no/maybe)\n"
          ]
        }
      ],
      "source": [
        "# PubMedQA Results comparison\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"PUBMEDQA EVALUATION RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\n{'Model':<25} {'Accuracy':>12} {'Correct':>10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Base Model':<25} {pubmedqa_base_accuracy:>12.2%} {pubmedqa_base_results['is_correct'].sum():>10}/{len(pubmedqa_base_results)}\")\n",
        "\n",
        "if pubmedqa_ft_accuracy is not None:\n",
        "    print(f\"{'PubMedQA Fine-tuned':<25} {pubmedqa_ft_accuracy:>12.2%} {pubmedqa_ft_results['is_correct'].sum():>10}/{len(pubmedqa_ft_results)}\")\n",
        "    print(\"\\n\" + \"-\" * 50)\n",
        "    improvement = pubmedqa_ft_accuracy - pubmedqa_base_accuracy\n",
        "    print(f\"Improvement: {improvement:+.2%}\")\n",
        "    print(f\"Random baseline: 33.3% (yes/no/maybe)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NngcUYcAgrdi"
      },
      "source": [
        "### Visualizing PubMedQA Results\n",
        "\n",
        "We create comparison charts for PubMedQA performance, including accuracy comparison and answer distribution analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "lYL_6f87grdi",
        "outputId": "7021dc7d-b4ea-4941-a31f-f6f3f382dd1d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PubMedQA Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: PubMedQA Model Comparison\n",
        "ax1 = axes[0]\n",
        "models = ['Base Model']\n",
        "accuracies = [pubmedqa_base_accuracy * 100]\n",
        "colors = ['steelblue']\n",
        "\n",
        "if pubmedqa_ft_accuracy is not None:\n",
        "    models.append('PubMedQA Fine-tuned')\n",
        "    accuracies.append(pubmedqa_ft_accuracy * 100)\n",
        "    colors.append('purple')\n",
        "\n",
        "bars = ax1.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax1.annotate(f'{acc:.1f}%',\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 5),\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax1.set_title('PubMedQA Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylim(0, 100)\n",
        "ax1.axhline(y=33.3, color='red', linestyle='--', alpha=0.5, label='Random Baseline (33.3%)')\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 2: PubMedQA Answer Distribution\n",
        "ax2 = axes[1]\n",
        "results_to_plot = pubmedqa_ft_results if pubmedqa_ft_results is not None else pubmedqa_base_results\n",
        "answer_counts = results_to_plot['predicted'].value_counts()\n",
        "correct_counts = results_to_plot['correct_answer'].value_counts()\n",
        "\n",
        "x = np.arange(3)\n",
        "width = 0.35\n",
        "\n",
        "answers = ['yes', 'no', 'maybe']\n",
        "predicted_vals = [answer_counts.get(a, 0) for a in answers]\n",
        "correct_vals = [correct_counts.get(a, 0) for a in answers]\n",
        "\n",
        "ax2.bar(x - width/2, predicted_vals, width, label='Predicted', color='coral', edgecolor='black')\n",
        "ax2.bar(x + width/2, correct_vals, width, label='Correct', color='mediumseagreen', edgecolor='black')\n",
        "\n",
        "ax2.set_xlabel('Answer', fontsize=12)\n",
        "ax2.set_ylabel('Count', fontsize=12)\n",
        "ax2.set_title('PubMedQA Answer Distribution', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(['Yes', 'No', 'Maybe'])\n",
        "ax2.legend()\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc2pXjSGgrdj"
      },
      "source": [
        "### Saving PubMedQA Evaluation Results\n",
        "\n",
        "We save the detailed PubMedQA evaluation results to a separate CSV file for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3-IYirXgrdj",
        "outputId": "b77b0543-783a-4b02-e6d8-b67a66000d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PubMedQA results saved to pubmedqa_evaluation_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Save PubMedQA evaluation results\n",
        "if pubmedqa_ft_results is not None:\n",
        "    pubmedqa_ft_results.to_csv('pubmedqa_evaluation_results.csv', index=False)\n",
        "    print(\"PubMedQA results saved to pubmedqa_evaluation_results.csv\")\n",
        "else:\n",
        "    pubmedqa_base_results.to_csv('pubmedqa_evaluation_results.csv', index=False)\n",
        "    print(\"PubMedQA base model results saved to pubmedqa_evaluation_results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_Xv1-rpgrdj"
      },
      "source": [
        "### Results Summary\n",
        "\n",
        "Comparing the models:\n",
        "- **Baseline**: Random guessing = 25% (4 choices)\n",
        "- **Base Model**: Pre-trained LLM with no medical fine-tuning\n",
        "- **Fine-Tuned Model**: Our medically-trained model\n",
        "\n",
        "The improvement shows the value of domain-specific fine-tuning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6d1NqBHgrdj"
      },
      "source": [
        "## Part 19: Visualization and Analysis\n",
        "\n",
        "### Performance Visualization\n",
        "\n",
        "We create two plots:\n",
        "\n",
        "1. **Model Comparison Bar Chart**:\n",
        "   - Shows accuracy of base vs fine-tuned model\n",
        "   - Includes random baseline (25%) for reference\n",
        "   - Quantifies improvement from fine-tuning\n",
        "\n",
        "2. **Answer Distribution**:\n",
        "   - Shows which answers (A, B, C, D) the model predicts\n",
        "   - Compares to true answer distribution\n",
        "   - Helps identify any prediction biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "sJZp7WrhVPKv",
        "outputId": "1443442c-28cb-4cd2-9273-f119af7fcf89"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Accuracy comparison bar chart\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Model Comparison\n",
        "ax1 = axes[0]\n",
        "models = ['Base Model']\n",
        "accuracies = [base_accuracy * 100]\n",
        "colors = ['steelblue']\n",
        "\n",
        "if ft_accuracy is not None:\n",
        "    models.append('Fine-tuned Model')\n",
        "    accuracies.append(ft_accuracy * 100)\n",
        "    colors.append('green')\n",
        "\n",
        "bars = ax1.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax1.annotate(f'{acc:.1f}%',\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 5),\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylim(0, 100)\n",
        "ax1.axhline(y=25, color='red', linestyle='--', alpha=0.5, label='Random Baseline (25%)')\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 2: Answer Distribution\n",
        "ax2 = axes[1]\n",
        "results_to_plot = ft_results if ft_results is not None else base_results\n",
        "answer_counts = results_to_plot['predicted'].value_counts()\n",
        "correct_counts = results_to_plot['correct_answer'].value_counts()\n",
        "\n",
        "x = np.arange(4)\n",
        "width = 0.35\n",
        "\n",
        "predicted_vals = [answer_counts.get(a, 0) for a in ['A', 'B', 'C', 'D']]\n",
        "correct_vals = [correct_counts.get(a, 0) for a in ['A', 'B', 'C', 'D']]\n",
        "\n",
        "ax2.bar(x - width/2, predicted_vals, width, label='Predicted', color='orange', edgecolor='black')\n",
        "ax2.bar(x + width/2, correct_vals, width, label='Correct', color='teal', edgecolor='black')\n",
        "\n",
        "ax2.set_xlabel('Answer Choice', fontsize=12)\n",
        "ax2.set_ylabel('Count', fontsize=12)\n",
        "ax2.set_title('Answer Distribution', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(['A', 'B', 'C', 'D'])\n",
        "ax2.legend()\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGcqDdm4VQN-",
        "outputId": "aedaec8e-ff81-4205-b4d8-011b37ac0723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performance by Medical Subject:\n",
            "==================================================\n",
            "                          Correct  Total  Accuracy\n",
            "subject                                           \n",
            "Pathology                       1      1     1.000\n",
            "Pharmacology                    3      3     1.000\n",
            "Radiology                       1      1     1.000\n",
            "Surgery                         4      5     0.800\n",
            "Biochemistry                    4      5     0.800\n",
            "Microbiology                    2      3     0.667\n",
            "Medicine                        1      2     0.500\n",
            "ENT                             1      2     0.500\n",
            "Gynaecology & Obstetrics        2      4     0.500\n",
            "Physiology                      1      2     0.500\n"
          ]
        }
      ],
      "source": [
        "# Analyze performance by medical subject\n",
        "results_df = ft_results if ft_results is not None else base_results\n",
        "\n",
        "subject_performance = results_df.groupby('subject').agg({\n",
        "    'is_correct': ['sum', 'count', 'mean']\n",
        "}).round(3)\n",
        "\n",
        "subject_performance.columns = ['Correct', 'Total', 'Accuracy']\n",
        "subject_performance = subject_performance.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\nPerformance by Medical Subject:\")\n",
        "print(\"=\" * 50)\n",
        "print(subject_performance.head(10).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5XTfJEfgrdj"
      },
      "source": [
        "### Performance by Medical Subject\n",
        "\n",
        "Breaking down accuracy by medical subject helps us:\n",
        "- Identify which specialties the model handles well\n",
        "- Find areas needing more training data\n",
        "- Understand domain-specific strengths/weaknesses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Sayrxmgrdj"
      },
      "source": [
        "## Part 20: Model Deployment Options\n",
        "\n",
        "### Merging Adapter into Base Model (Optional)\n",
        "\n",
        "There are two ways to deploy a LoRA-finetuned model:\n",
        "\n",
        "**Option 1: Base + Adapter (Recommended)**\n",
        "- Keep base model and adapter separate\n",
        "- Smaller files (~10-50MB adapter)\n",
        "- Same inference speed and memory\n",
        "- Easy to version control and share\n",
        "\n",
        "**Option 2: Merged Model**\n",
        "- Combine adapter into base model\n",
        "- Single model file (~4-8GB)\n",
        "- Simpler deployment (no adapter loading)\n",
        "- Larger storage requirement\n",
        "\n",
        "For most use cases, Option 1 is better. Only merge if you need a standalone model file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbpWXcPBVROc",
        "outputId": "86b882dd-53f5-449e-c94b-5d8221622cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging adapter into base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:397: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Merged model saved to: ./medical_llm_merged\n",
            "total 1020476\n",
            "drwxr-xr-x 2 root root       4096 Jan  5 06:05 .\n",
            "drwxr-xr-x 1 root root       4096 Jan  5 06:04 ..\n",
            "-rw-r--r-- 1 root root       1364 Jan  5 06:04 config.json\n",
            "-rw-r--r-- 1 root root        230 Jan  5 06:04 generation_config.json\n",
            "-rw-r--r-- 1 root root 1027676612 Jan  5 06:05 model.safetensors\n",
            "-rw-r--r-- 1 root root        459 Jan  5 06:05 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      50646 Jan  5 06:05 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root   17210019 Jan  5 06:05 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "# Merging adapters (optional - uncomment to run)\n",
        "# Note: This requires more memory and may not work on free Colab\n",
        "\n",
        "MERGE_MODEL = True  # Set to True to merge\n",
        "\n",
        "if MERGE_MODEL and HAS_FINETUNED:\n",
        "    print(\"Merging adapter into base model...\")\n",
        "\n",
        "    # Merge and unload\n",
        "    merged_model = finetuned_model.merge_and_unload()\n",
        "\n",
        "    # Save merged model\n",
        "    MERGED_PATH = \"./medical_llm_merged\"\n",
        "    merged_model.save_pretrained(MERGED_PATH)\n",
        "    tokenizer.save_pretrained(MERGED_PATH)\n",
        "\n",
        "    print(f\"\\n Merged model saved to: {MERGED_PATH}\")\n",
        "    !ls -la {MERGED_PATH}\n",
        "else:\n",
        "    print(\"Skipping model merge (set MERGE_MODEL=True to enable)\")\n",
        "    print(\"\\nNote: For deployment, you can either:\")\n",
        "    print(\"  1. Use base model + adapter (smaller files, same memory at inference)\")\n",
        "    print(\"  2. Merge into single model (larger files, simpler deployment)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlWaokw6grdk"
      },
      "source": [
        "## Part 23: Saving Results\n",
        "\n",
        "### Exporting Evaluation Results\n",
        "\n",
        "Save detailed results to CSV for:\n",
        "- Further analysis in other tools\n",
        "- Sharing with team members\n",
        "- Creating reports and visualizations\n",
        "- Identifying specific failure cases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b2I2KnqVWLT"
      },
      "outputs": [],
      "source": [
        "# Save evaluation results\n",
        "if ft_results is not None:\n",
        "    ft_results.to_csv('evaluation_results.csv', index=False)\n",
        "    print(\"Results saved to evaluation_results.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypY7zaxQgrdk"
      },
      "source": [
        "### Key Takeaways\n",
        "\n",
        "1. **Parameter-Efficient Fine-Tuning Works**: LoRA achieves good results with <1% trainable parameters\n",
        "2. **Quantization Enables Training on Limited Hardware**: 4-bit loading fits billion-parameter models on consumer GPUs\n",
        "3. **Domain-Specific Fine-Tuning Improves Performance**: Medical fine-tuning significantly outperforms base models\n",
        "4. **Instruction Formatting Matters**: Consistent format (Alpaca/ChatML) helps models learn the task\n",
        "5. **Task-Specific Adapters**: Training separate adapters for MedMCQA (4-choice MCQ) and PubMedQA (yes/no/maybe) allows specialized performance\n",
        "\n",
        "### Models Trained\n",
        "\n",
        "| Dataset | Task Type | Output Directory | Random Baseline |\n",
        "|---------|-----------|------------------|-----------------|\n",
        "| MedMCQA | Multiple Choice (A/B/C/D) | `./medical_llm_finetuned/` | 25% |\n",
        "| PubMedQA | Yes/No/Maybe | `./pubmedqa_llm_finetuned/` | 33.3% |\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Increase training**: Run for more epochs with larger datasets\n",
        "- **Try different models**: Test Llama-3, Mistral, or medical-specific base models\n",
        "- **Experiment with hyperparameters**: Adjust LoRA rank, learning rate, batch size\n",
        "- **Add more datasets**: Include MedQA, MMLU-Medical, or other domain-specific data\n",
        "- **Deploy as API**: Create a web service using FastAPI or similar\n",
        "- **Fine-tune for specific specialties**: Focus on cardiology, radiology, etc.\n",
        "- **Multi-task learning**: Combine both datasets for a unified medical QA model\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [PEFT Documentation](https://huggingface.co/docs/peft)\n",
        "- [TRL Documentation](https://huggingface.co/docs/trl)\n",
        "- [LoRA Paper](https://arxiv.org/abs/2106.09685)\n",
        "- [MedMCQA Dataset](https://huggingface.co/datasets/openlifescienceai/medmcqa)\n",
        "- [PubMedQA Dataset](https://huggingface.co/datasets/qiaojin/PubMedQA)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "anais",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0085742b2d9d42ba802ba6ea9713f144": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00b3a2c8e90047fabf3a57ac8e9a9a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a452d72fb1d4ee4bc39e91d816a53d1",
            "placeholder": "​",
            "style": "IPY_MODEL_b5f90946e1984339a4394b29fcf5467d",
            "value": " 230/230 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "03abb3b638654def95ae7af5471c0bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0459724541cb4abcb9c5d89d7f8a22a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07286d26e1ae4630af17a3d229a1e34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07a3348d8e5d468f865000434bd8bb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0802ed9f7e264ee580adaf3c3510da14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c13c934337144d784c1b0612c23173d",
              "IPY_MODEL_1ec69db623d64d5a90162f61d16cfe22",
              "IPY_MODEL_88ae3d1c40974b2596511340d8b968b4"
            ],
            "layout": "IPY_MODEL_fc55a9096344479c9046cb3bf1af1e1a"
          }
        },
        "0bd879ce1ac948a2809b871c9705fc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d98c42f303e45519a38d45b02b7b788": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03abb3b638654def95ae7af5471c0bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_39a6199fa846407cac2c4bfe8f84f289",
            "value": " 6150/6150 [00:00&lt;00:00, 59338.89 examples/s]"
          }
        },
        "0df7725ee21f4ea2a0c08096a786ff95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc5e8ba4114478caa9707a109a41b41",
            "max": 6150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7006fd8f18d6451d89fdbd08de473835",
            "value": 6150
          }
        },
        "16388c3aebfb465d8d2f67ff8ca8634d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a19773f6a1a483da6bd354eae410a59",
            "placeholder": "​",
            "style": "IPY_MODEL_07a3348d8e5d468f865000434bd8bb09",
            "value": "Generating train split: 100%"
          }
        },
        "19d9ec607e6c4c198e7a67cd646c4524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac3243de5e9d4736ad7281c3131c9061",
            "placeholder": "​",
            "style": "IPY_MODEL_71b4471e2d624fae9308e0e7ac3252a7",
            "value": " 10.7k/? [00:00&lt;00:00, 158kB/s]"
          }
        },
        "1cfe28de38594dfdb74e109335f33951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74bc9d6ebebe45e499e2b7173d747a9f",
              "IPY_MODEL_74ca7b0d542c451093e7bc057e6d0209",
              "IPY_MODEL_b65f3d53219e4ece927d4d49584b1a67"
            ],
            "layout": "IPY_MODEL_dda5bf1bd5344064b4f93373e1ea0eef"
          }
        },
        "1d113ef14b9244528012f849fe3ac4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d3de473a5874ba6aa941635da008ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5041dc8acdb49f790915cb3fb45e878",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c66ff70150846a1b091e5157d1e6eca",
            "value": 1
          }
        },
        "1dc5e8ba4114478caa9707a109a41b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec69db623d64d5a90162f61d16cfe22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_998216b95aa44e5cbee854e43f667c51",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5899459e8cb349ce89aa70cb478145cd",
            "value": 2471645608
          }
        },
        "21a5d7ebfc744a66aa6c593a49f9584f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece3681a37f54828a618f2cf3c3b3dbf",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0085742b2d9d42ba802ba6ea9713f144",
            "value": 1000
          }
        },
        "22fa35dc64d5445b85c3e5b02fc4297f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24158f9c09214035bea33bafa84c601d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16388c3aebfb465d8d2f67ff8ca8634d",
              "IPY_MODEL_21a5d7ebfc744a66aa6c593a49f9584f",
              "IPY_MODEL_6b051c9750744616848b342bbf412b93"
            ],
            "layout": "IPY_MODEL_f1d5eaf573094405b4edb9223ea2febf"
          }
        },
        "248f0e0eb13e41f59b0835cb39c92c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ad59baf42343d1bbcbee9575bc808e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ac9cdff37564c33ba13776f4e66f703": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6572713305040bbb209c1516f31b293",
            "placeholder": "​",
            "style": "IPY_MODEL_a435e25655104fac9faf86aaa8281641",
            "value": "README.md: "
          }
        },
        "38405a34a3a847158629dc53a44a6126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a6199fa846407cac2c4bfe8f84f289": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c6ca45699214de8934a376e42c97dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e760193293c48d4915ac8fa2c4bb06b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa77d19f9e445cb94fad2ae72c52e34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411d3bbd8c1245b4952526110cd1a9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e760193293c48d4915ac8fa2c4bb06b",
            "placeholder": "​",
            "style": "IPY_MODEL_71cf4adbd90b48e683fbffb1330ca0e6",
            "value": "Map: 100%"
          }
        },
        "481b228bf0f143f7ab04a1d2ec489147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_751c89c7b2f542b6ad48504e0fe2dd74",
            "placeholder": "​",
            "style": "IPY_MODEL_faf78f318f5945ae973ca9a3869a369e",
            "value": " 182822/182822 [00:01&lt;00:00, 120889.42 examples/s]"
          }
        },
        "4835d76f9bdd487bab47f02a35c01700": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be9b69b9f8542ca8496bf72a803a715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de3c79caa98749e5bee86810d744fc30",
              "IPY_MODEL_0df7725ee21f4ea2a0c08096a786ff95",
              "IPY_MODEL_0d98c42f303e45519a38d45b02b7b788"
            ],
            "layout": "IPY_MODEL_e5e1408e008040c9a35dcf992847e3de"
          }
        },
        "4c90df0bfcc84d43bd858beefa0739c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b08aaacdca44a6847d17fbb6268e3b",
            "placeholder": "​",
            "style": "IPY_MODEL_791e18568bb8484cacafdb36f4c3762c",
            "value": "pqa_labeled/train-00000-of-00001.parquet: 100%"
          }
        },
        "4d863c12d6404071bad8dea446d10900": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4daa2ede459a4c99a216647e54a3f4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ac9cdff37564c33ba13776f4e66f703",
              "IPY_MODEL_855b3304e3b8403b9e91a38f9c8f5e50",
              "IPY_MODEL_878c0faa3fd2436fb51e9b90ec2dcad0"
            ],
            "layout": "IPY_MODEL_d29480e9162e4e9f92d76cebc315575c"
          }
        },
        "4e8f9ac4b0f4401fb3ca396b8c7ed389": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db3e67d2393648eb8a5336f1136097dd",
              "IPY_MODEL_609431c6fa5a4f289253a7488cc34665",
              "IPY_MODEL_7ac13e9714aa46aa9de2bcb0eaaafe13"
            ],
            "layout": "IPY_MODEL_d9e0642afe5e42249a5e207745fcf407"
          }
        },
        "4eb5acde0f5245e7b3da6b3a996ceffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f414020e76e41599f48987a0a2cdcaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52ad538d6a154b79ab7e343fdc2bcd99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a275ac5f3b8445cb82052903a5670971",
            "placeholder": "​",
            "style": "IPY_MODEL_fac032f5eaf94f5fa7fb4ecba8c99350",
            "value": " 50/50 [00:00&lt;00:00, 907.62 examples/s]"
          }
        },
        "52e908813fd24b019b5717bf98b9bd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a456e4fe24b24baabd063c2bf7dff5e6",
            "placeholder": "​",
            "style": "IPY_MODEL_1d113ef14b9244528012f849fe3ac4f0",
            "value": "data/validation-00000-of-00001.parquet: 100%"
          }
        },
        "542f954119614d42b33f35ae064613e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5899459e8cb349ce89aa70cb478145cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a3c8f62333745958dd2b7fc9a4d97b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bcecbaefed54c929e236b3caecdb022": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c13c934337144d784c1b0612c23173d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b7967ad5774ffa899762e5e8821f65",
            "placeholder": "​",
            "style": "IPY_MODEL_5a3c8f62333745958dd2b7fc9a4d97b0",
            "value": "model.safetensors: 100%"
          }
        },
        "6082206484f342d3a49dad9a6b29c0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609431c6fa5a4f289253a7488cc34665": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d863c12d6404071bad8dea446d10900",
            "max": 936358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_542f954119614d42b33f35ae064613e3",
            "value": 936358
          }
        },
        "62ec8ad9440245f3848bd498dbf2687c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64669c74b86b4ef6af4c18c72b7e78fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899cd14d1e3c4fe09651df1ccf2d56c1",
            "max": 1476104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9b8e68197fb4d03b8324eab8b07d890",
            "value": 1476104
          }
        },
        "647d314157d148e2bbb5f7175fee0018": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf171f8ff6a14d28a5f3050d12b84d08",
            "max": 1075513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4787f79b78c4b338206ea4fd9439e7c",
            "value": 1075513
          }
        },
        "64d3ced5a1e0489897733d0119a83460": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6526e18414ac49609bcbcc56e63a20cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6940c7e5bfe64a05aeff79b0cae7798b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f994665e0c8544f7a58023a02a115e17",
              "IPY_MODEL_6be9a21a7add423c82e6768d8024def0",
              "IPY_MODEL_52ad538d6a154b79ab7e343fdc2bcd99"
            ],
            "layout": "IPY_MODEL_8674ae90863b4e6bb2783c8488fd6b21"
          }
        },
        "6a452d72fb1d4ee4bc39e91d816a53d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b051c9750744616848b342bbf412b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec7d3a15516144008e955972ddc5a117",
            "placeholder": "​",
            "style": "IPY_MODEL_64d3ced5a1e0489897733d0119a83460",
            "value": " 1000/1000 [00:00&lt;00:00, 17337.71 examples/s]"
          }
        },
        "6b13d52938f546c0b5c8223c799ccf12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be9a21a7add423c82e6768d8024def0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bcecbaefed54c929e236b3caecdb022",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79255675012a4137aed1403173b2b004",
            "value": 50
          }
        },
        "7006fd8f18d6451d89fdbd08de473835": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71b4471e2d624fae9308e0e7ac3252a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71cf4adbd90b48e683fbffb1330ca0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7221019f436945dbae5e42c09c3e9b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52e908813fd24b019b5717bf98b9bd5a",
              "IPY_MODEL_64669c74b86b4ef6af4c18c72b7e78fb",
              "IPY_MODEL_aad2cb1613ce4eeabc8ada5d0a089d50"
            ],
            "layout": "IPY_MODEL_3fa77d19f9e445cb94fad2ae72c52e34"
          }
        },
        "74bc9d6ebebe45e499e2b7173d747a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf9b8eab54a74bb08abbc0e03fb8adf8",
            "placeholder": "​",
            "style": "IPY_MODEL_9822f5407d7f4f16a052dd489f023908",
            "value": "data/train-00000-of-00001.parquet: 100%"
          }
        },
        "74ca7b0d542c451093e7bc057e6d0209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fa35dc64d5445b85c3e5b02fc4297f",
            "max": 85899025,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4230c3e8645449182271c0e7d08af12",
            "value": 85899025
          }
        },
        "751c89c7b2f542b6ad48504e0fe2dd74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791e18568bb8484cacafdb36f4c3762c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79255675012a4137aed1403173b2b004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79690fcab1d54487aad96a9f09726aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_892fefde024a4eab9dd4bf4734f55ab6",
            "placeholder": "​",
            "style": "IPY_MODEL_d557ffdb4d1547c1b6d259e2f01b1acb",
            "value": "Generating train split: 100%"
          }
        },
        "7a19773f6a1a483da6bd354eae410a59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac13e9714aa46aa9de2bcb0eaaafe13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef1f604436945e6bea7bf95fecefbbc",
            "placeholder": "​",
            "style": "IPY_MODEL_b849309de6ea4d7a875a7324e0465229",
            "value": " 936k/936k [00:00&lt;00:00, 2.50MB/s]"
          }
        },
        "7b7cea93605e43ada08cb62df997359e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8c64f562b2478d9d684fd1f01574fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84306a6cbb8a441a9d6f005be6c13e55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84de363856054b4784a0b923d10466d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97db9684633465d872b8a1546292068",
            "placeholder": "​",
            "style": "IPY_MODEL_f081433133a64c0a84c581648bab7b7b",
            "value": "README.md: "
          }
        },
        "855b3304e3b8403b9e91a38f9c8f5e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f414020e76e41599f48987a0a2cdcaf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9b081dccb984009bacec2bb22f1c7f7",
            "value": 1
          }
        },
        "865d31d1d07641c2959532bde9d8fb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84de363856054b4784a0b923d10466d7",
              "IPY_MODEL_1d3de473a5874ba6aa941635da008ad4",
              "IPY_MODEL_19d9ec607e6c4c198e7a67cd646c4524"
            ],
            "layout": "IPY_MODEL_9f85361550154325869c0a0560339933"
          }
        },
        "8674ae90863b4e6bb2783c8488fd6b21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878c0faa3fd2436fb51e9b90ec2dcad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38405a34a3a847158629dc53a44a6126",
            "placeholder": "​",
            "style": "IPY_MODEL_a08b50178479484c8dbab6781ca4d335",
            "value": " 5.19k/? [00:00&lt;00:00, 359kB/s]"
          }
        },
        "879dc52623454fca8d0ea10eaab7d376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8bf2c0f71894684ba49387eeee68f84",
            "placeholder": "​",
            "style": "IPY_MODEL_c4617834f9c848f096dd57ae29696a82",
            "value": "Generating validation split: 100%"
          }
        },
        "88ae3d1c40974b2596511340d8b968b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3c8e68048ed45aeb7dbab38bcb3996d",
            "placeholder": "​",
            "style": "IPY_MODEL_07286d26e1ae4630af17a3d229a1e34d",
            "value": " 2.47G/2.47G [00:28&lt;00:00, 206MB/s]"
          }
        },
        "892fefde024a4eab9dd4bf4734f55ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899cd14d1e3c4fe09651df1ccf2d56c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d04acb553714d31af5fa3fecce3c632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9822f5407d7f4f16a052dd489f023908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "998216b95aa44e5cbee854e43f667c51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac135d1ab3647c08f4e73dec77361f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c66ff70150846a1b091e5157d1e6eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f85361550154325869c0a0560339933": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08b50178479484c8dbab6781ca4d335": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10eef411a2a4c28906213c580f44f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d241abed062d4d70bc3786b4da6104f4",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e6e3fde244425b9647009e007fabdf",
            "value": 50
          }
        },
        "a14120e822b64ac8b690534374a2d3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2190d4c8a8247c68683b1b35332abed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f0c5a5937f499094e8cfa11ba95348",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd879ce1ac948a2809b871c9705fc5e",
            "value": " 4183/4183 [00:00&lt;00:00, 52241.31 examples/s]"
          }
        },
        "a275ac5f3b8445cb82052903a5670971": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a435e25655104fac9faf86aaa8281641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a456e4fe24b24baabd063c2bf7dff5e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6572713305040bbb209c1516f31b293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97db9684633465d872b8a1546292068": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad2cb1613ce4eeabc8ada5d0a089d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6082206484f342d3a49dad9a6b29c0c4",
            "placeholder": "​",
            "style": "IPY_MODEL_b45d429fb9d3496c9d100dca887dfdd5",
            "value": " 1.48M/1.48M [00:00&lt;00:00, 5.16MB/s]"
          }
        },
        "ab2a6bd12f3348dbad26b5c53117fbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab310a12274041869b6c9806df03f49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b13d52938f546c0b5c8223c799ccf12",
            "placeholder": "​",
            "style": "IPY_MODEL_a14120e822b64ac8b690534374a2d3a3",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 234kB/s]"
          }
        },
        "ac3243de5e9d4736ad7281c3131c9061": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae4e7011398342368bc16fd55954734b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c8c64f562b2478d9d684fd1f01574fc",
            "max": 230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26ad59baf42343d1bbcbee9575bc808e",
            "value": 230
          }
        },
        "b115c0de6a15454583a5c240c412c854": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c90df0bfcc84d43bd858beefa0739c9",
              "IPY_MODEL_647d314157d148e2bbb5f7175fee0018",
              "IPY_MODEL_ab310a12274041869b6c9806df03f49e"
            ],
            "layout": "IPY_MODEL_4835d76f9bdd487bab47f02a35c01700"
          }
        },
        "b45d429fb9d3496c9d100dca887dfdd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5041dc8acdb49f790915cb3fb45e878": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b5f90946e1984339a4394b29fcf5467d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b65f3d53219e4ece927d4d49584b1a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248f0e0eb13e41f59b0835cb39c92c4e",
            "placeholder": "​",
            "style": "IPY_MODEL_62ec8ad9440245f3848bd498dbf2687c",
            "value": " 85.9M/85.9M [00:01&lt;00:00, 82.2MB/s]"
          }
        },
        "b7043d4417e74192a59e9338b029c1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f47d60b1b6e3491798d3b945d0545681",
            "max": 4183,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d04acb553714d31af5fa3fecce3c632",
            "value": 4183
          }
        },
        "b849309de6ea4d7a875a7324e0465229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bef1f604436945e6bea7bf95fecefbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e7eecc35414c90ae5b98957c6bdce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_411d3bbd8c1245b4952526110cd1a9dc",
              "IPY_MODEL_a10eef411a2a4c28906213c580f44f50",
              "IPY_MODEL_f75a0b078ff14d20ad8e379c7eb8d09a"
            ],
            "layout": "IPY_MODEL_7b7cea93605e43ada08cb62df997359e"
          }
        },
        "c4617834f9c848f096dd57ae29696a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4787f79b78c4b338206ea4fd9439e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6f0c5a5937f499094e8cfa11ba95348": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ae32ad9a63427487826b85355998d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce17332596954ea594ef12a253393448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf171f8ff6a14d28a5f3050d12b84d08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf5437b6df9943119d0ec498219bca19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6526e18414ac49609bcbcc56e63a20cf",
            "placeholder": "​",
            "style": "IPY_MODEL_ab2a6bd12f3348dbad26b5c53117fbdc",
            "value": "generation_config.json: 100%"
          }
        },
        "cf9b8eab54a74bb08abbc0e03fb8adf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1017b61cf87473db2f0402f757dca6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d241abed062d4d70bc3786b4da6104f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d29480e9162e4e9f92d76cebc315575c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b412f853d44efba481a560bb685fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c8e68048ed45aeb7dbab38bcb3996d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d5c3036d33407cb3b1900440aab7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b412f853d44efba481a560bb685fa3",
            "max": 182822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0459724541cb4abcb9c5d89d7f8a22a0",
            "value": 182822
          }
        },
        "d557ffdb4d1547c1b6d259e2f01b1acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e0642afe5e42249a5e207745fcf407": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3e67d2393648eb8a5336f1136097dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e74ed699665d4f71ac6b06cf3932923b",
            "placeholder": "​",
            "style": "IPY_MODEL_e173c3337a5a41a4b714a5101fc1c821",
            "value": "data/test-00000-of-00001.parquet: 100%"
          }
        },
        "dd31f5ab14894978afda826859ad1fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79690fcab1d54487aad96a9f09726aed",
              "IPY_MODEL_d4d5c3036d33407cb3b1900440aab7a8",
              "IPY_MODEL_481b228bf0f143f7ab04a1d2ec489147"
            ],
            "layout": "IPY_MODEL_eb203833dc8a48f3b660dceb1f1adca1"
          }
        },
        "dda5bf1bd5344064b4f93373e1ea0eef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de3c79caa98749e5bee86810d744fc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac135d1ab3647c08f4e73dec77361f7",
            "placeholder": "​",
            "style": "IPY_MODEL_d1017b61cf87473db2f0402f757dca6d",
            "value": "Generating test split: 100%"
          }
        },
        "e173c3337a5a41a4b714a5101fc1c821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2e6e3fde244425b9647009e007fabdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4a1b456c6774c648d7387a8ca209af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_879dc52623454fca8d0ea10eaab7d376",
              "IPY_MODEL_b7043d4417e74192a59e9338b029c1ea",
              "IPY_MODEL_a2190d4c8a8247c68683b1b35332abed"
            ],
            "layout": "IPY_MODEL_ce17332596954ea594ef12a253393448"
          }
        },
        "e5e1408e008040c9a35dcf992847e3de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b08aaacdca44a6847d17fbb6268e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e716f28ac9224bbfb61fc8135f85ae8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e74ed699665d4f71ac6b06cf3932923b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b081dccb984009bacec2bb22f1c7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb203833dc8a48f3b660dceb1f1adca1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba0333843a04336a5f03abea1a07f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf5437b6df9943119d0ec498219bca19",
              "IPY_MODEL_ae4e7011398342368bc16fd55954734b",
              "IPY_MODEL_00b3a2c8e90047fabf3a57ac8e9a9a0b"
            ],
            "layout": "IPY_MODEL_e716f28ac9224bbfb61fc8135f85ae8c"
          }
        },
        "ec7d3a15516144008e955972ddc5a117": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece3681a37f54828a618f2cf3c3b3dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f081433133a64c0a84c581648bab7b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1d5eaf573094405b4edb9223ea2febf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4230c3e8645449182271c0e7d08af12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f47d60b1b6e3491798d3b945d0545681": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75a0b078ff14d20ad8e379c7eb8d09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ae32ad9a63427487826b85355998d4",
            "placeholder": "​",
            "style": "IPY_MODEL_4eb5acde0f5245e7b3da6b3a996ceffe",
            "value": " 50/50 [00:00&lt;00:00, 863.89 examples/s]"
          }
        },
        "f8b7967ad5774ffa899762e5e8821f65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8bf2c0f71894684ba49387eeee68f84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f994665e0c8544f7a58023a02a115e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84306a6cbb8a441a9d6f005be6c13e55",
            "placeholder": "​",
            "style": "IPY_MODEL_3c6ca45699214de8934a376e42c97dc8",
            "value": "Map: 100%"
          }
        },
        "f9b8e68197fb4d03b8324eab8b07d890": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fac032f5eaf94f5fa7fb4ecba8c99350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faf78f318f5945ae973ca9a3869a369e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc55a9096344479c9046cb3bf1af1e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}